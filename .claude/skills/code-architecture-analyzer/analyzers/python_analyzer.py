#!/usr/bin/env python3
"""
Pythoné¡¹ç›®ä¸“ç”¨æ¶æ„åˆ†æå™¨
ä¸“é—¨åˆ†æPythoné¡¹ç›®çš„æ¶æ„æ¨¡å¼ã€ä»£ç è´¨é‡ã€æœ€ä½³å®è·µ
æ”¯æŒWebåº”ç”¨ã€æ•°æ®ç§‘å­¦ã€æœºå™¨å­¦ä¹ ã€CLIå·¥å…·ç­‰é¡¹ç›®ç±»å‹
"""

import ast
import re
import json
import subprocess
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Set
from dataclasses import dataclass
from enum import Enum
import configparser

class PythonProjectType(Enum):
    WEB_APP = "Web Application"
    DATA_SCIENCE = "Data Science"
    MACHINE_LEARNING = "Machine Learning"
    CLI_TOOL = "CLI Tool"
    LIBRARY = "Python Library"
    API_SERVICE = "API Service"
    MICROSERVICE = "Microservice"
    DESKTOP_APP = "Desktop Application"
    GAME = "Game Development"

class PythonFramework(Enum):
    DJANGO = "Django"
    FLASK = "Flask"
    FASTAPI = "FastAPI"
    STREAMLIT = "Streamlit"
    GRADIO = "Gradio"
    JUPYTER = "Jupyter Notebook"
    PANDAS = "Pandas"
    NUMPY = "NumPy"
    TENSORFLOW = "TensorFlow"
    PYTORCH = "PyTorch"
    SCIKIT_LEARN = "Scikit-learn"
    CLICK = "Click"
    ARGPARSE = "Argparse"
    TKINTER = "Tkinter"
    PYQT = "PyQt"
    KIVY = "Kivy"

class PythonArchitecturePattern(Enum):
    MVC = "Model-View-Controller"
    MVT = "Model-View-Template"
    REPOSITORY = "Repository Pattern"
    FACTORY = "Factory Pattern"
    SINGLETON = "Singleton Pattern"
    OBSERVER = "Observer Pattern"
    STRATEGY = "Strategy Pattern"
    ADAPTER = "Adapter Pattern"
    DECORATOR = "Decorator Pattern"
    DEPENDENCY_INJECTION = "Dependency Injection"
    COMMAND = "Command Pattern"
    STATE_MACHINE = "State Machine"
    PIPELINE = "Pipeline Pattern"
    PLUGIN = "Plugin Architecture"

class CodeQualityIssue(Enum):
    LONG_FUNCTIONS = "Long Functions (>50 lines)"
    LARGE_CLASSES = "Large Classes (>300 lines)"
    COMPLEXITY_HIGH = "High Cyclomatic Complexity"
    MISSING_DOCS = "Missing Documentation"
    TYPE_HINTS_MISSING = "Missing Type Hints"
    HARDCODED_VALUES = "Hardcoded Values"
    EXCEPTION_HANDLING = "Poor Exception Handling"
    DUPLICATE_CODE = "Code Duplication"
    NAMING_CONVENTION = "Naming Convention Issues"
    IMPORT_ISSUES = "Import Organization Issues"

class PythonBestPractice(Enum):
    VIRTUAL_ENV = "Virtual Environment Usage"
    DEPENDENCY_MANAGEMENT = "Dependency Management"
    TESTING = "Unit Testing Present"
    LOGGING = "Logging Implementation"
    CONFIG_MANAGEMENT = "Configuration Management"
    ASYNC_PROGRAMMING = "Async Programming"
    CONTEXT_MANAGERS = "Context Managers Usage"
    PROPERTY_DECORATORS = "Property Decorators"
    DATA_CLASSES = "Data Classes Usage"
    TYPE_HINTS = "Type Hints Usage"

@dataclass
class PythonModuleInfo:
    name: str
    file_path: str
    lines_of_code: int
    functions: List[str]
    classes: List[str]
    imports: List[str]
    complexity_score: float
    documentation_coverage: float
    type_hints_coverage: float
    dependencies: List[str]

@dataclass
class PythonArchitectureAnalysis:
    project_type: PythonProjectType
    frameworks: List[PythonFramework]
    patterns: List[PythonArchitecturePattern]
    quality_issues: List[CodeQualityIssue]
    best_practices: List[PythonBestPractice]
    modules: List[PythonModuleInfo]
    dependencies: Dict[str, str]
    project_structure: Dict[str, List[str]]
    test_coverage: Dict[str, float]
    recommendations: List[str]
    quality_score: float
    security_issues: List[str]

class PythonArchitectureAnalyzer:
    def __init__(self, project_path: Path):
        self.project_path = project_path
        self.excluded_dirs = {
            '.git', '__pycache__', 'node_modules', '.pytest_cache',
            '.venv', 'venv', 'env', '.env', 'build', 'dist', 'egg-info'
        }

    def analyze(self) -> PythonArchitectureAnalysis:
        """æ‰§è¡ŒPythoné¡¹ç›®çš„å…¨é¢æ¶æ„åˆ†æ"""

        # è¯†åˆ«é¡¹ç›®ç±»å‹
        project_type = self._identify_project_type()

        # æ£€æµ‹æ¡†æ¶
        frameworks = self._detect_frameworks()

        # æ£€æµ‹æ¶æ„æ¨¡å¼
        patterns = self._detect_patterns()

        # åˆ†æä»£ç è´¨é‡é—®é¢˜
        quality_issues = self._analyze_quality_issues()

        # è¯„ä¼°æœ€ä½³å®è·µ
        best_practices = self._evaluate_best_practices()

        # åˆ†ææ¨¡å—
        modules = self._analyze_modules()

        # åˆ†æä¾èµ–
        dependencies = self._analyze_dependencies()

        # åˆ†æé¡¹ç›®ç»“æ„
        project_structure = self._analyze_project_structure()

        # åˆ†ææµ‹è¯•è¦†ç›–ç‡
        test_coverage = self._analyze_test_coverage()

        # å®‰å…¨æ£€æŸ¥
        security_issues = self._security_analysis()

        # ç”Ÿæˆå»ºè®®
        recommendations = self._generate_recommendations(
            project_type, frameworks, patterns, quality_issues, best_practices, security_issues
        )

        # è®¡ç®—è´¨é‡è¯„åˆ†
        quality_score = self._calculate_quality_score(
            patterns, quality_issues, best_practices, test_coverage
        )

        return PythonArchitectureAnalysis(
            project_type=project_type,
            frameworks=frameworks,
            patterns=patterns,
            quality_issues=quality_issues,
            best_practices=best_practices,
            modules=modules,
            dependencies=dependencies,
            project_structure=project_structure,
            test_coverage=test_coverage,
            recommendations=recommendations,
            quality_score=quality_score,
            security_issues=security_issues
        )

    def _identify_project_type(self) -> PythonProjectType:
        """è¯†åˆ«Pythoné¡¹ç›®ç±»å‹"""
        indicators = {
            PythonProjectType.WEB_APP: [
                'requirements.txt', 'manage.py', 'app.py', 'server.py',
                'wsgi.py', 'asgi.py', 'urls.py', 'views.py'
            ],
            PythonProjectType.DATA_SCIENCE: [
                'requirements.txt', 'Jupyterfile', 'jupyter/', 'notebooks/',
                '.ipynb', 'pandas', 'numpy', 'matplotlib'
            ],
            PythonProjectType.MACHINE_LEARNING: [
                'model.py', 'train.py', 'predict.py', 'requirements.txt',
                'tensorflow', 'torch', 'sklearn', 'keras', 'datasets/'
            ],
            PythonProjectType.CLI_TOOL: [
                'setup.py', 'Click', 'argparse', 'typer', 'main.py',
                '__main__.py', 'console_scripts'
            ],
            PythonProjectType.LIBRARY: [
                'setup.py', 'pyproject.toml', 'src/', 'tests/',
                'README.md', 'LICENSE'
            ],
            PythonProjectType.API_SERVICE: [
                'api/', 'main.py', 'requirements.txt', 'fastapi',
                'flask', 'django', 'endpoints/', 'routes/'
            ],
            PythonProjectType.DESKTOP_APP: [
                'tkinter', 'pyqt', 'kivy', 'pygame', 'gui/',
                'main.py', 'app.py'
            ]
        }

        # æ£€æŸ¥æ–‡ä»¶å’Œç›®å½•
        project_files = []
        for file_path in self.project_path.rglob("*"):
            if file_path.is_file() and not any(excluded in str(file_path) for excluded in self.excluded_dirs):
                project_files.append(str(file_path).lower())

        # æ£€æŸ¥ç›®å½•ç»“æ„
        project_dirs = [d.name.lower() for d in self.project_path.iterdir() if d.is_dir()]

        # è®¡ç®—æ¯ç§é¡¹ç›®ç±»å‹çš„åŒ¹é…åº¦
        type_scores = {}
        for project_type, files in indicators.items():
            score = sum(1 for indicator in files if any(indicator in f for f in project_files + project_dirs))
            type_scores[project_type] = score

        # è¿”å›å¾—åˆ†æœ€é«˜çš„é¡¹ç›®ç±»å‹
        if type_scores:
            return max(type_scores, key=type_scores.get)
        return PythonProjectType.WEB_APP  # é»˜è®¤å€¼

    def _detect_frameworks(self) -> List[PythonFramework]:
        """æ£€æµ‹ä½¿ç”¨çš„Pythonæ¡†æ¶"""
        frameworks = []

        # æ£€æŸ¥ä¾èµ–æ–‡ä»¶
        dependency_files = [
            'requirements.txt', 'pyproject.toml', 'Pipfile',
            'setup.py', 'environment.yml'
        ]

        for dep_file in dependency_files:
            file_path = self.project_path / dep_file
            if file_path.exists():
                try:
                    content = file_path.read_text(encoding='utf-8').lower()
                    frameworks.extend(self._detect_frameworks_from_content(content))
                except:
                    continue

        # æ£€æŸ¥Pythonæ–‡ä»¶ä¸­çš„å¯¼å…¥
        for py_file in self.project_path.rglob("*.py"):
            if not any(excluded in str(py_file) for excluded in self.excluded_dirs):
                try:
                    content = py_file.read_text(encoding='utf-8')
                    frameworks.extend(self._detect_frameworks_from_content(content))
                except:
                    continue

        return list(set(frameworks))  # å»é‡

    def _detect_frameworks_from_content(self, content: str) -> List[PythonFramework]:
        """ä»å†…å®¹ä¸­æ£€æµ‹æ¡†æ¶"""
        frameworks = []

        framework_indicators = {
            PythonFramework.DJANGO: ['django', 'manage.py', 'urls.py', 'views.py'],
            PythonFramework.FLASK: ['flask', 'app = flask(', 'flask.ext'],
            PythonFramework.FASTAPI: ['fastapi', 'from fastapi', 'app = fastapi'],
            PythonFramework.STREAMLIT: ['streamlit', 'st.', 'streamlit.'],
            PythonFramework.GRADIO: ['gradio', 'gr.', 'gradio.'],
            PythonFramework.JUPYTER: ['jupyter', 'ipython', 'notebook'],
            PythonFramework.PANDAS: ['pandas', 'pd = pandas', 'import pandas'],
            PythonFramework.NUMPY: ['numpy', 'np = numpy', 'import numpy'],
            PythonFramework.TENSORFLOW: ['tensorflow', 'tf = tensorflow', 'import tensorflow'],
            PythonFramework.PYTORCH: ['torch', 'pytorch', 'import torch'],
            PythonFramework.SCIKIT_LEARN: ['sklearn', 'scikit-learn', 'import sklearn'],
            PythonFramework.CLICK: ['click', '@click.', 'import click'],
            PythonFramework.ARGPARSE: ['argparse', 'ArgumentParser', 'import argparse'],
            PythonFramework.TKINTER: ['tkinter', 'Tk()', 'import tkinter'],
            PythonFramework.PYQT: ['pyqt', 'PyQt', 'from pyqt'],
            PythonFramework.KIVY: ['kivy', 'from kivy', 'import kivy']
        }

        for framework, indicators in framework_indicators.items():
            if any(indicator in content for indicator in indicators):
                frameworks.append(framework)

        return frameworks

    def _detect_patterns(self) -> List[PythonArchitecturePattern]:
        """æ£€æµ‹æ¶æ„æ¨¡å¼"""
        patterns = []

        # åˆ†æPythonæ–‡ä»¶
        py_files = [
            f for f in self.project_path.rglob("*.py")
            if not any(excluded in str(f) for excluded in self.excluded_dirs)
        ]

        # åˆå¹¶æ‰€æœ‰ä»£ç å†…å®¹è¿›è¡Œåˆ†æ
        all_code = ""
        for py_file in py_files:
            try:
                all_code += py_file.read_text(encoding='utf-8') + "\n"
            except:
                continue

        # æ£€æµ‹å„ç§æ¨¡å¼
        if self._detect_mvc_pattern(py_files):
            patterns.append(PythonArchitecturePattern.MVC)

        if self._detect_mvt_pattern(py_files):
            patterns.append(PythonArchitecturePattern.MVT)

        if self._detect_repository_pattern(all_code):
            patterns.append(PythonArchitecturePattern.REPOSITORY)

        if self._detect_factory_pattern(all_code):
            patterns.append(PythonArchitecturePattern.FACTORY)

        if self._detect_singleton_pattern(all_code):
            patterns.append(PythonArchitecturePattern.SINGLETON)

        if self._detect_observer_pattern(all_code):
            patterns.append(PythonArchitecturePattern.OBSERVER)

        if self._detect_strategy_pattern(all_code):
            patterns.append(PythonArchitecturePattern.STRATEGY)

        if self._detect_adapter_pattern(all_code):
            patterns.append(PythonArchitecturePattern.ADAPTER)

        if self._detect_decorator_pattern(all_code):
            patterns.append(PythonArchitecturePattern.DECORATOR)

        if self._detect_dependency_injection_pattern(all_code):
            patterns.append(PythonArchitecturePattern.DEPENDENCY_INJECTION)

        if self._detect_command_pattern(all_code):
            patterns.append(PythonArchitecturePattern.COMMAND)

        if self._detect_state_machine_pattern(all_code):
            patterns.append(PythonArchitecturePattern.STATE_MACHINE)

        if self._detect_pipeline_pattern(all_code):
            patterns.append(PythonArchitecturePattern.PIPELINE)

        if self._detect_plugin_pattern(py_files):
            patterns.append(PythonArchitecturePattern.PLUGIN)

        return patterns

    def _analyze_quality_issues(self) -> List[CodeQualityIssue]:
        """åˆ†æä»£ç è´¨é‡é—®é¢˜"""
        issues = []

        py_files = [
            f for f in self.project_path.rglob("*.py")
            if not any(excluded in str(f) for excluded in self.excluded_dirs)
        ]

        for py_file in py_files:
            try:
                with open(py_file, 'r', encoding='utf-8') as f:
                    content = f.read()

                # è§£æAST
                tree = ast.parse(content)

                # æ£€æŸ¥é•¿å‡½æ•°
                if self._has_long_functions(tree):
                    issues.append(CodeQualityIssue.LONG_FUNCTIONS)

                # æ£€æŸ¥å¤§ç±»
                if self._has_large_classes(tree):
                    issues.append(CodeQualityIssue.LARGE_CLASSES)

                # æ£€æŸ¥å¤æ‚åº¦
                if self._has_high_complexity(tree):
                    issues.append(CodeQualityIssue.COMPLEXITY_HIGH)

                # æ£€æŸ¥æ–‡æ¡£
                if self._missing_documentation(tree):
                    issues.append(CodeQualityIssue.MISSING_DOCS)

                # æ£€æŸ¥ç±»å‹æç¤º
                if self._missing_type_hints(tree):
                    issues.append(CodeQualityIssue.TYPE_HINTS_MISSING)

                # æ£€æŸ¥ç¡¬ç¼–ç å€¼
                if self._has_hardcoded_values(content):
                    issues.append(CodeQualityIssue.HARDCODED_VALUES)

                # æ£€æŸ¥å¼‚å¸¸å¤„ç†
                if self._poor_exception_handling(tree):
                    issues.append(CodeQualityIssue.EXCEPTION_HANDLING)

                # æ£€æŸ¥å‘½åè§„èŒƒ
                if self._naming_convention_issues(tree):
                    issues.append(CodeQualityIssue.NAMING_CONVENTION)

            except:
                continue

        # å»é‡
        return list(set(issues))

    def _evaluate_best_practices(self) -> List[PythonBestPractice]:
        """è¯„ä¼°æœ€ä½³å®è·µ"""
        practices = []

        # æ£€æŸ¥è™šæ‹Ÿç¯å¢ƒ
        if self._has_virtual_environment():
            practices.append(PythonBestPractice.VIRTUAL_ENV)

        # æ£€æŸ¥ä¾èµ–ç®¡ç†
        if self._has_dependency_management():
            practices.append(PythonBestPractice.DEPENDENCY_MANAGEMENT)

        # æ£€æŸ¥æµ‹è¯•
        if self._has_unit_tests():
            practices.append(PythonBestPractice.TESTING)

        # æ£€æŸ¥æ—¥å¿—
        if self._has_logging_implementation():
            practices.append(PythonBestPractice.LOGGING)

        # æ£€æŸ¥é…ç½®ç®¡ç†
        if self._has_configuration_management():
            practices.append(PythonBestPractice.CONFIG_MANAGEMENT)

        # æ£€æŸ¥å¼‚æ­¥ç¼–ç¨‹
        if self._has_async_programming():
            practices.append(PythonBestPractice.ASYNC_PROGRAMMING)

        # æ£€æŸ¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨
        if self._has_context_managers():
            practices.append(PythonBestPractice.CONTEXT_MANAGERS)

        # æ£€æŸ¥å±æ€§è£…é¥°å™¨
        if self._has_property_decorators():
            practices.append(PythonBestPractice.PROPERTY_DECORATORS)

        # æ£€æŸ¥æ•°æ®ç±»
        if self._has_data_classes():
            practices.append(PythonBestPractice.DATA_CLASSES)

        # æ£€æŸ¥ç±»å‹æç¤º
        if self._has_type_hints_usage():
            practices.append(PythonBestPractice.TYPE_HINTS)

        return practices

    def _analyze_modules(self) -> List[PythonModuleInfo]:
        """åˆ†æPythonæ¨¡å—"""
        modules = []

        py_files = [
            f for f in self.project_path.rglob("*.py")
            if not any(excluded in str(f) for excluded in self.excluded_dirs)
        ]

        for py_file in py_files:
            try:
                with open(py_file, 'r', encoding='utf-8') as f:
                    content = f.read()

                # è§£æAST
                tree = ast.parse(content)

                # æå–æ¨¡å—ä¿¡æ¯
                module_name = py_file.stem
                file_path = str(py_file.relative_to(self.project_path))
                lines_of_code = len([line for line in content.split('\n') if line.strip()])

                functions = [node.name for node in ast.walk(tree) if isinstance(node, ast.FunctionDef)]
                classes = [node.name for node in ast.walk(tree) if isinstance(node, ast.ClassDef)]
                imports = self._extract_imports(tree)

                complexity_score = self._calculate_complexity_score(tree)
                documentation_coverage = self._calculate_doc_coverage(tree)
                type_hints_coverage = self._calculate_type_hints_coverage(tree)
                dependencies = self._extract_module_dependencies(tree)

                modules.append(PythonModuleInfo(
                    name=module_name,
                    file_path=file_path,
                    lines_of_code=lines_of_code,
                    functions=functions,
                    classes=classes,
                    imports=imports,
                    complexity_score=complexity_score,
                    documentation_coverage=documentation_coverage,
                    type_hints_coverage=type_hints_coverage,
                    dependencies=dependencies
                ))

            except:
                continue

        return modules

    def _analyze_dependencies(self) -> Dict[str, str]:
        """åˆ†æé¡¹ç›®ä¾èµ–"""
        dependencies = {}

        # åˆ†ærequirements.txt
        req_file = self.project_path / 'requirements.txt'
        if req_file.exists():
            try:
                content = req_file.read_text(encoding='utf-8')
                for line in content.split('\n'):
                    line = line.strip()
                    if line and not line.startswith('#'):
                        if '==' in line:
                            pkg, version = line.split('==', 1)
                            dependencies[pkg] = version
                        else:
                            dependencies[line] = 'latest'
            except:
                pass

        # åˆ†æpyproject.toml
        pyproject_file = self.project_path / 'pyproject.toml'
        if pyproject_file.exists():
            try:
                content = pyproject_file.read_text(encoding='utf-8')
                # ç®€åŒ–ç‰ˆTOMLè§£æ
                import re
                deps_match = re.search(r'dependencies\s*=\s*\[(.*?)\]', content, re.DOTALL)
                if deps_match:
                    deps_section = deps_match.group(1)
                    for dep in re.findall(r'["\']([^"\']+)["\']', deps_section):
                        if '>=' in dep or '==' in dep or '<=' in dep:
                            pkg, version = re.split(r'[<>=]+', dep, 1)
                            dependencies[pkg] = dep
                        else:
                            dependencies[dep] = 'latest'
            except:
                pass

        return dependencies

    def _analyze_project_structure(self) -> Dict[str, List[str]]:
        """åˆ†æé¡¹ç›®ç»“æ„"""
        structure = {
            "source_code": [],
            "tests": [],
            "configuration": [],
            "documentation": [],
            "scripts": [],
            "data": [],
            "models": []
        }

        for item in self.project_path.rglob("*"):
            if item.is_file() and not any(excluded in str(item) for excluded in self.excluded_dirs):
                rel_path = str(item.relative_to(self.project_path))

                if item.suffix == '.py':
                    if 'test' in item.name.lower() or 'tests' in str(item.parent).lower():
                        structure["tests"].append(rel_path)
                    else:
                        structure["source_code"].append(rel_path)

                elif item.suffix in ['.txt', '.yaml', '.yml', '.toml', '.ini', '.cfg', '.conf']:
                    structure["configuration"].append(rel_path)

                elif item.suffix in ['.md', '.rst', '.txt'] and ('readme' in item.name.lower() or 'doc' in str(item.parent).lower()):
                    structure["documentation"].append(rel_path)

                elif item.suffix in ['.sh', '.bat', '.ps1']:
                    structure["scripts"].append(rel_path)

                elif item.suffix in ['.csv', '.json', '.pkl', '.parquet', '.h5']:
                    structure["data"].append(rel_path)

                elif item.suffix in ['.pkl', '.pth', '.pt', '.h5', '.pb', '.onnx']:
                    structure["models"].append(rel_path)

        return structure

    def _analyze_test_coverage(self) -> Dict[str, float]:
        """åˆ†ææµ‹è¯•è¦†ç›–ç‡"""
        coverage = {}

        # æ£€æŸ¥æ˜¯å¦æœ‰pytesté…ç½®
        pytest_files = [
            'pytest.ini', 'pyproject.toml', 'setup.cfg', '.coveragerc'
        ]

        for config_file in pytest_files:
            file_path = self.project_path / config_file
            if file_path.exists():
                try:
                    content = file_path.read_text(encoding='utf-8')
                    # å°è¯•è¿è¡Œpytestè·å–è¦†ç›–ç‡
                    if self._can_run_pytest():
                        result = subprocess.run(
                            ['pytest', '--cov=.', '--cov-report=term-missing'],
                            cwd=self.project_path,
                            capture_output=True,
                            text=True,
                            timeout=30
                        )
                        if result.returncode == 0:
                            coverage_output = result.stdout
                            # è§£æè¦†ç›–ç‡è¾“å‡º
                            coverage_match = re.search(r'TOTAL\s+\d+\s+\d+\s+(\d+)%', coverage_output)
                            if coverage_match:
                                coverage['overall'] = float(coverage_match.group(1))
                except:
                    pass
                break

        # è®¡ç®—æµ‹è¯•æ–‡ä»¶æ•°é‡
        test_files = list(self.project_path.rglob("*test*.py"))
        source_files = [
            f for f in self.project_path.rglob("*.py")
            if not any(excluded in str(f) for excluded in self.excluded_dirs)
            and 'test' not in str(f).lower()
        ]

        if source_files:
            coverage['test_to_source_ratio'] = len(test_files) / len(source_files)
        else:
            coverage['test_to_source_ratio'] = 0.0

        return coverage

    def _security_analysis(self) -> List[str]:
        """å®‰å…¨åˆ†æ"""
        security_issues = []

        py_files = [
            f for f in self.project_path.rglob("*.py")
            if not any(excluded in str(f) for excluded in self.excluded_dirs)
        ]

        for py_file in py_files:
            try:
                with open(py_file, 'r', encoding='utf-8') as f:
                    content = f.read()

                # æ£€æŸ¥ç¡¬ç¼–ç å¯†é’¥
                if self._has_hardcoded_secrets(content):
                    security_issues.append(f"Hardcoded secrets found in {py_file.name}")

                # æ£€æŸ¥SQLæ³¨å…¥é£é™©
                if self._has_sql_injection_risks(content):
                    security_issues.append(f"Potential SQL injection in {py_file.name}")

                # æ£€æŸ¥eval/execä½¿ç”¨
                if self._has_dangerous_functions(content):
                    security_issues.append(f"Dangerous functions (eval/exec) in {py_file.name}")

                # æ£€æŸ¥pickleä¸å®‰å…¨ä½¿ç”¨
                if self._has_unsafe_pickle(content):
                    security_issues.append(f"Unsafe pickle usage in {py_file.name}")

            except:
                continue

        return list(set(security_issues))

    def _generate_recommendations(self, project_type: PythonProjectType,
                                 frameworks: List[PythonFramework],
                                 patterns: List[PythonArchitecturePattern],
                                 quality_issues: List[CodeQualityIssue],
                                 best_practices: List[PythonBestPractice],
                                 security_issues: List[str]) -> List[str]:
        """ç”Ÿæˆæ”¹è¿›å»ºè®®"""
        recommendations = []

        # åŸºäºé¡¹ç›®ç±»å‹çš„å»ºè®®
        if project_type == PythonProjectType.WEB_APP:
            recommendations.extend([
                "ğŸŒ **APIè®¾è®¡**: ä½¿ç”¨RESTful APIè®¾è®¡åŸåˆ™å’ŒOpenAPIè§„èŒƒ",
                "ğŸ” **å®‰å…¨å®ç°**: æ·»åŠ è®¤è¯ã€æˆæƒã€HTTPSã€CSRFä¿æŠ¤",
                "ğŸ“Š **æ€§èƒ½ä¼˜åŒ–**: å®ç°ç¼“å­˜ã€æ•°æ®åº“ä¼˜åŒ–ã€å¼‚æ­¥å¤„ç†",
                "ğŸ§ª **æµ‹è¯•è¦†ç›–**: æ·»åŠ å•å…ƒæµ‹è¯•ã€é›†æˆæµ‹è¯•ã€APIæµ‹è¯•"
            ])

        elif project_type == PythonProjectType.MACHINE_LEARNING:
            recommendations.extend([
                "ğŸ¤– **æ¨¡å‹ç®¡ç†**: ä½¿ç”¨MLflowæˆ–DVCç®¡ç†æ¨¡å‹ç‰ˆæœ¬",
                "ğŸ“ˆ **å®éªŒè·Ÿè¸ª**: å®ç°å®éªŒæ—¥å¿—è®°å½•å’Œå‚æ•°ç®¡ç†",
                "ğŸš€ **éƒ¨ç½²å‡†å¤‡**: å®¹å™¨åŒ–æ¨¡å‹æœåŠ¡ï¼Œå®ç°æ¨¡å‹ç›‘æ§",
                "ğŸ”§ **æ•°æ®å¤„ç†**: ä½¿ç”¨DVCæˆ–ç±»ä¼¼å·¥å…·ç®¡ç†æ•°æ®é›†ç‰ˆæœ¬"
            ])

        elif project_type == PythonProjectType.DATA_SCIENCE:
            recommendations.extend([
                "ğŸ“Š **æ•°æ®å¤„ç†**: ä½¿ç”¨Pandasã€NumPyä¼˜åŒ–æ•°æ®å¤„ç†æµç¨‹",
                "ğŸ“ˆ **å¯è§†åŒ–**: æ·»åŠ Matplotlibã€Seabornã€Plotlyå¯è§†åŒ–",
                "ğŸ“ **æ–‡æ¡£å®Œå–„**: æ·»åŠ æ•°æ®å­—å…¸ã€å¤„ç†æµç¨‹è¯´æ˜",
                "ğŸ”„ **è‡ªåŠ¨åŒ–**: ä½¿ç”¨Jupyteræˆ–è‡ªåŠ¨åŒ–è„šæœ¬å¤„ç†é‡å¤ä»»åŠ¡"
            ])

        # åŸºäºè´¨é‡é—®é¢˜çš„å»ºè®®
        if CodeQualityIssue.LONG_FUNCTIONS in quality_issues:
            recommendations.append("ğŸ“ **å‡½æ•°æ‹†åˆ†**: å°†é•¿å‡½æ•°æ‹†åˆ†ä¸ºæ›´å°çš„åŠŸèƒ½å•å…ƒ")

        if CodeQualityIssue.MISSING_DOCS in quality_issues:
            recommendations.append("ğŸ“ **æ·»åŠ æ–‡æ¡£**: ä¸ºå‡½æ•°å’Œç±»æ·»åŠ docstringæ–‡æ¡£")

        if CodeQualityIssue.TYPE_HINTS_MISSING in quality_issues:
            recommendations.append("ğŸ’¡ **ç±»å‹æç¤º**: æ·»åŠ ç±»å‹æç¤ºæé«˜ä»£ç å¯è¯»æ€§å’ŒIDEæ”¯æŒ")

        if CodeQualityIssue.HARDCODED_VALUES in quality_issues:
            recommendations.append("âš™ï¸ **é…ç½®ç®¡ç†**: å°†ç¡¬ç¼–ç å€¼ç§»åŠ¨åˆ°é…ç½®æ–‡ä»¶")

        # åŸºäºæœ€ä½³å®è·µçš„å»ºè®®
        if PythonBestPractice.TESTING not in best_practices:
            recommendations.append("ğŸ§ª **æ·»åŠ æµ‹è¯•**: å®ç°å•å…ƒæµ‹è¯•å’Œé›†æˆæµ‹è¯•")

        if PythonBestPractice.LOGGING not in best_practices:
            recommendations.append("ğŸ“‹ **å®ç°æ—¥å¿—**: æ·»åŠ ç»“æ„åŒ–æ—¥å¿—è®°å½•")

        if PythonBestPractice.VIRTUAL_ENV not in best_practices:
            recommendations.append("ğŸ **è™šæ‹Ÿç¯å¢ƒ**: ä½¿ç”¨è™šæ‹Ÿç¯å¢ƒç®¡ç†ä¾èµ–")

        # åŸºäºå®‰å…¨é—®é¢˜çš„å»ºè®®
        if security_issues:
            recommendations.extend([
                "ğŸ”’ **å®‰å…¨å®¡è®¡**: æ£€æŸ¥å¹¶ä¿®å¤ç¡¬ç¼–ç å¯†é’¥å’Œæ•æ„Ÿä¿¡æ¯",
                "ğŸ›¡ï¸ **è¾“å…¥éªŒè¯**: å®ç°è¾“å…¥éªŒè¯å’Œè¾“å‡ºç¼–ç ",
                "ğŸ” **ä¾èµ–æ›´æ–°**: å®šæœŸæ›´æ–°ä¾èµ–åŒ…ä¿®å¤å®‰å…¨æ¼æ´"
            ])

        # åŸºäºæ¶æ„æ¨¡å¼çš„å»ºè®®
        if not patterns:
            recommendations.append("ğŸ—ï¸ **æ¶æ„è®¾è®¡**: è€ƒè™‘åº”ç”¨MVCã€Repositoryæˆ–Factoryæ¨¡å¼")

        # é€šç”¨å»ºè®®
        recommendations.extend([
            "ğŸ“Š **ä»£ç è´¨é‡**: ä½¿ç”¨pylintã€blackã€isortç­‰å·¥å…·æé«˜ä»£ç è´¨é‡",
            "ğŸ”„ **CI/CD**: è®¾ç½®æŒç»­é›†æˆå’Œè‡ªåŠ¨åŒ–æµ‹è¯•",
            "ğŸ“š **æ–‡æ¡£å®Œå–„**: æ·»åŠ READMEã€APIæ–‡æ¡£ã€ä½¿ç”¨ç¤ºä¾‹",
            "ğŸ› **é”™è¯¯å¤„ç†**: å®ç°å®Œå–„çš„å¼‚å¸¸å¤„ç†å’Œé”™è¯¯æ—¥å¿—",
            "âš¡ **æ€§èƒ½ç›‘æ§**: æ·»åŠ æ€§èƒ½ç›‘æ§å’ŒæŒ‡æ ‡æ”¶é›†"
        ])

        return recommendations

    def _calculate_quality_score(self, patterns: List[PythonArchitecturePattern],
                                 quality_issues: List[CodeQualityIssue],
                                 best_practices: List[PythonBestPractice],
                                 test_coverage: Dict[str, float]) -> float:
        """è®¡ç®—é¡¹ç›®è´¨é‡è¯„åˆ†"""
        base_score = 50.0

        # æ¶æ„æ¨¡å¼åŠ åˆ† (æ¯ä¸ªæ¨¡å¼+4åˆ†)
        pattern_score = len(patterns) * 4

        # æœ€ä½³å®è·µåŠ åˆ† (æ¯ä¸ªå®è·µ+3åˆ†)
        practice_score = len(best_practices) * 3

        # è´¨é‡é—®é¢˜æ‰£åˆ† (æ¯ä¸ªé—®é¢˜-6åˆ†)
        issue_penalty = len(quality_issues) * 6

        # æµ‹è¯•è¦†ç›–ç‡åŠ åˆ†
        coverage_score = test_coverage.get('overall', 0) * 0.2

        # æµ‹è¯•æ–‡ä»¶æ¯”ä¾‹åŠ åˆ†
        test_ratio_score = test_coverage.get('test_to_source_ratio', 0) * 10

        final_score = base_score + pattern_score + practice_score - issue_penalty + coverage_score + test_ratio_score
        return max(0.0, min(100.0, final_score))

    # æ¨¡å¼æ£€æµ‹æ–¹æ³•
    def _detect_mvc_pattern(self, py_files: List[Path]) -> bool:
        """æ£€æµ‹MVCæ¨¡å¼"""
        has_model = any('model' in str(f).lower() for f in py_files)
        has_view = any('view' in str(f).lower() for f in py_files)
        has_controller = any('controller' in str(f).lower() for f in py_files)
        return has_model and has_view and has_controller

    def _detect_mvt_pattern(self, py_files: List[Path]) -> bool:
        """æ£€æµ‹MVTæ¨¡å¼ (Djangoç‰¹æœ‰)"""
        has_model = any('model' in str(f).lower() for f in py_files)
        has_view = any('view' in str(f).lower() for f in py_files)
        has_template = any('template' in str(f).lower() for f in py_files)
        return has_model and has_view and has_template

    def _detect_repository_pattern(self, code_content: str) -> bool:
        """æ£€æµ‹Repositoryæ¨¡å¼"""
        repo_indicators = [
            r'class.*Repository',
            r'def.*find_by',
            r'def.*save\(',
            r'def.*delete\(',
            r'def.*get_by'
        ]
        return any(re.search(pattern, code_content, re.IGNORECASE) for pattern in repo_indicators)

    def _detect_factory_pattern(self, code_content: str) -> bool:
        """æ£€æµ‹Factoryæ¨¡å¼"""
        factory_indicators = [
            r'class.*Factory',
            r'def.*create.*\(',
            r'def.*build.*\(',
            r'Factory\(\)'
        ]
        return any(re.search(pattern, code_content, re.IGNORECASE) for pattern in factory_indicators)

    def _detect_singleton_pattern(self, code_content: str) -> bool:
        """æ£€æµ‹Singletonæ¨¡å¼"""
        singleton_indicators = [
            r'_instance\s*=',
            r'def.*__new__',
            r'def.*get_instance',
            r'@classmethod'
        ]
        return any(re.search(pattern, code_content, re.IGNORECASE) for pattern in singleton_indicators)

    def _detect_observer_pattern(self, code_content: str) -> bool:
        """æ£€æµ‹Observeræ¨¡å¼"""
        observer_indicators = [
            r'@observer|@subscribe',
            r'notify\s*\(',
            r'attach\s*\(',
            r'detach\s*\(',
            r'subject\.'
        ]
        return any(re.search(pattern, code_content, re.IGNORECASE) for pattern in observer_indicators)

    def _detect_strategy_pattern(self, code_content: str) -> bool:
        """æ£€æµ‹Strategyæ¨¡å¼"""
        strategy_indicators = [
            r'class.*Strategy',
            r'def.*execute.*\(',
            r'strategy\s*=',
            r'StrategyPattern'
        ]
        return any(re.search(pattern, code_content, re.IGNORECASE) for pattern in strategy_indicators)

    def _detect_adapter_pattern(self, code_content: str) -> bool:
        """æ£€æµ‹Adapteræ¨¡å¼"""
        adapter_indicators = [
            r'class.*Adapter',
            r'def.*adapt.*\(',
            r'interface\s+.*Adapter'
        ]
        return any(re.search(pattern, code_content, re.IGNORECASE) for pattern in adapter_indicators)

    def _detect_decorator_pattern(self, code_content: str) -> bool:
        """æ£€æµ‹Decoratoræ¨¡å¼"""
        return '@' in code_content and 'def ' in code_content

    def _detect_dependency_injection_pattern(self, code_content: str) -> bool:
        """æ£€æµ‹ä¾èµ–æ³¨å…¥æ¨¡å¼"""
        di_indicators = [
            r'def.*__init__\([^)]*\*args[^)]*\*\*kwargs',
            r'inject\s*=',
            r'container\.'
        ]
        return any(re.search(pattern, code_content, re.IGNORECASE) for pattern in di_indicators)

    def _detect_command_pattern(self, code_content: str) -> bool:
        """æ£€æµ‹Commandæ¨¡å¼"""
        command_indicators = [
            r'class.*Command',
            r'def.*execute.*\(',
            r'def.*undo.*\(',
            r'Command.*execute'
        ]
        return any(re.search(pattern, code_content, re.IGNORECASE) for pattern in command_indicators)

    def _detect_state_machine_pattern(self, code_content: str) -> bool:
        """æ£€æµ‹çŠ¶æ€æœºæ¨¡å¼"""
        state_machine_indicators = [
            r'class.*State',
            r'current_state\s*=',
            r'def.*transition.*\(',
            r'switch.*state'
        ]
        return any(re.search(pattern, code_content, re.IGNORECASE) for pattern in state_machine_indicators)

    def _detect_pipeline_pattern(self, code_content: str) -> bool:
        """æ£€æµ‹Pipelineæ¨¡å¼"""
        pipeline_indicators = [
            r'class.*Pipeline',
            r'pipeline\s*=',
            r'def.*fit_transform',
            r'def.*process.*\('
        ]
        return any(re.search(pattern, code_content, re.IGNORECASE) for pattern in pipeline_indicators)

    def _detect_plugin_pattern(self, py_files: List[Path]) -> bool:
        """æ£€æµ‹Pluginæ¶æ„æ¨¡å¼"""
        plugin_indicators = ['plugin', 'extension', 'module', 'addons']
        return any(any(indicator in str(f).lower() for indicator in plugin_indicators) for f in py_files)

    # è´¨é‡é—®é¢˜æ£€æµ‹æ–¹æ³•
    def _has_long_functions(self, tree: ast.AST) -> bool:
        """æ£€æµ‹é•¿å‡½æ•°"""
        for node in ast.walk(tree):
            if isinstance(node, ast.FunctionDef):
                if hasattr(node, 'end_lineno') and node.end_lineno:
                    lines = node.end_lineno - node.lineno + 1
                else:
                    lines = len(node.body)  # ç®€åŒ–è®¡ç®—
                if lines > 50:
                    return True
        return False

    def _has_large_classes(self, tree: ast.AST) -> bool:
        """æ£€æµ‹å¤§ç±»"""
        for node in ast.walk(tree):
            if isinstance(node, ast.ClassDef):
                if hasattr(node, 'end_lineno') and node.end_lineno:
                    lines = node.end_lineno - node.lineno + 1
                else:
                    lines = len([n for n in ast.walk(node) if isinstance(n, (ast.FunctionDef, ast.ClassDef))])
                if lines > 300:
                    return True
        return False

    def _has_high_complexity(self, tree: ast.AST) -> bool:
        """æ£€æµ‹é«˜å¤æ‚åº¦"""
        def calculate_complexity(node):
            complexity = 1
            for child in ast.walk(node):
                if isinstance(child, (ast.If, ast.While, ast.For, ast.AsyncFor)):
                    complexity += 1
                elif isinstance(child, ast.ExceptHandler):
                    complexity += 1
                elif isinstance(child, ast.BoolOp):
                    complexity += len(child.values) - 1
            return complexity

        for node in ast.walk(tree):
            if isinstance(node, ast.FunctionDef):
                if calculate_complexity(node) > 10:
                    return True
        return False

    def _missing_documentation(self, tree: ast.AST) -> bool:
        """æ£€æµ‹ç¼ºå¤±æ–‡æ¡£"""
        for node in ast.walk(tree):
            if isinstance(node, (ast.FunctionDef, ast.ClassDef)):
                if not ast.get_docstring(node):
                    return True
        return False

    def _missing_type_hints(self, tree: ast.AST) -> bool:
        """æ£€æµ‹ç¼ºå¤±ç±»å‹æç¤º"""
        for node in ast.walk(tree):
            if isinstance(node, ast.FunctionDef):
                if not node.returns:
                    return True
                if not all(arg.annotation for arg in node.args.args):
                    return True
        return False

    def _has_hardcoded_values(self, content: str) -> bool:
        """æ£€æµ‹ç¡¬ç¼–ç å€¼"""
        # æ£€æŸ¥URLã€å¯†é’¥ã€æ•°æ®åº“è¿æ¥å­—ç¬¦ä¸²ç­‰
        hardcoded_patterns = [
            r'http[s]?://[^\s\']+',
            r'password\s*=\s*[\'\"][^\'\"]+[\'\"]',
            r'api_key\s*=\s*[\'\"][^\'\"]+[\'\"]',
            r'secret\s*=\s*[\'\"][^\'\"]+[\'\"]',
            r'localhost:\d+',
            r'\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}'
        ]
        return any(re.search(pattern, content, re.IGNORECASE) for pattern in hardcoded_patterns)

    def _poor_exception_handling(self, tree: ast.AST) -> bool:
        """æ£€æµ‹å¼‚å¸¸å¤„ç†é—®é¢˜"""
        for node in ast.walk(tree):
            if isinstance(node, ast.ExceptHandler):
                if node.type is None:  # except:
                    return True
                if isinstance(node.type, ast.Name) and node.type.id == 'Exception':
                    if not node.body or len(node.body) == 1:
                        # åªæœ‰passæˆ–ç®€å•çš„print
                        if isinstance(node.body[0], ast.Pass) or \
                           (isinstance(node.body[0], ast.Expr) and
                            isinstance(node.body[0].value, ast.Call)):
                            return True
        return False

    def _naming_convention_issues(self, tree: ast.AST) -> bool:
        """æ£€æµ‹å‘½åè§„èŒƒé—®é¢˜"""
        for node in ast.walk(tree):
            if isinstance(node, ast.FunctionDef):
                if not node.name.islower() or '_' not in node.name:
                    if not node.name.startswith('_'):  # å…è®¸ç§æœ‰æ–¹æ³•
                        return True
            elif isinstance(node, ast.ClassDef):
                if not node.name[0].isupper():
                    return True
        return False

    # æœ€ä½³å®è·µæ£€æµ‹æ–¹æ³•
    def _has_virtual_environment(self) -> bool:
        """æ£€æµ‹è™šæ‹Ÿç¯å¢ƒ"""
        venv_indicators = [
            'venv/', 'env/', '.venv/', 'virtualenv/',
            'conda.yaml', 'environment.yml', 'Pipfile'
        ]
        return any((self.project_path / indicator).exists() for indicator in venv_indicators)

    def _has_dependency_management(self) -> bool:
        """æ£€æµ‹ä¾èµ–ç®¡ç†"""
        dep_files = ['requirements.txt', 'pyproject.toml', 'Pipfile', 'setup.py']
        return any((self.project_path / f).exists() for f in dep_files)

    def _has_unit_tests(self) -> bool:
        """æ£€æµ‹å•å…ƒæµ‹è¯•"""
        test_patterns = [
            'test_', '_test.py', 'tests/', 'conftest.py',
            'pytest.ini', 'tox.ini'
        ]
        return any(
            (self.project_path / pattern).exists() or
            any(pattern in str(f).lower() for f in self.project_path.rglob("*.py"))
            for pattern in test_patterns
        )

    def _has_logging_implementation(self) -> bool:
        """æ£€æµ‹æ—¥å¿—å®ç°"""
        for py_file in self.project_path.rglob("*.py"):
            if not any(excluded in str(py_file) for excluded in self.excluded_dirs):
                try:
                    content = py_file.read_text(encoding='utf-8')
                    if 'import logging' in content or 'logging.getLogger' in content:
                        return True
                except:
                    continue
        return False

    def _has_configuration_management(self) -> bool:
        """æ£€æµ‹é…ç½®ç®¡ç†"""
        config_patterns = [
            'config.py', 'settings.py', '.env', 'config.yaml',
            'config.yml', 'settings.ini', 'config.json'
        ]
        return any((self.project_path / pattern).exists() for pattern in config_patterns)

    def _has_async_programming(self) -> bool:
        """æ£€æµ‹å¼‚æ­¥ç¼–ç¨‹"""
        for py_file in self.project_path.rglob("*.py"):
            if not any(excluded in str(py_file) for excluded in self.excluded_dirs):
                try:
                    content = py_file.read_text(encoding='utf-8')
                    if 'async def' in content or 'await ' in content:
                        return True
                except:
                    continue
        return False

    def _has_context_managers(self) -> bool:
        """æ£€æµ‹ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
        for py_file in self.project_path.rglob("*.py"):
            if not any(excluded in str(py_file) for excluded in self.excluded_dirs):
                try:
                    with open(py_file, 'r', encoding='utf-8') as f:
                        content = f.read()
                        tree = ast.parse(content)

                        for node in ast.walk(tree):
                            if isinstance(node, ast.With):
                                return True
                except:
                    continue
        return False

    def _has_property_decorators(self) -> bool:
        """æ£€æµ‹å±æ€§è£…é¥°å™¨"""
        for py_file in self.project_path.rglob("*.py"):
            if not any(excluded in str(py_file) for excluded in self.excluded_dirs):
                try:
                    content = py_file.read_text(encoding='utf-8')
                    if '@property' in content:
                        return True
                except:
                    continue
        return False

    def _has_data_classes(self) -> bool:
        """æ£€æµ‹æ•°æ®ç±»"""
        for py_file in self.project_path.rglob("*.py"):
            if not any(excluded in str(py_file) for excluded in self.excluded_dirs):
                try:
                    content = py_file.read_text(encoding='utf-8')
                    if '@dataclass' in content or 'dataclasses' in content:
                        return True
                except:
                    continue
        return False

    def _has_type_hints_usage(self) -> bool:
        """æ£€æµ‹ç±»å‹æç¤ºä½¿ç”¨"""
        for py_file in self.project_path.rglob("*.py"):
            if not any(excluded in str(py_file) for excluded in self.excluded_dirs):
                try:
                    with open(py_file, 'r', encoding='utf-8') as f:
                        content = f.read()
                        tree = ast.parse(content)

                        for node in ast.walk(tree):
                            if isinstance(node, ast.FunctionDef) and node.returns:
                                return True
                            elif isinstance(node, ast.AnnAssign):  # å¸¦ç±»å‹æ³¨è§£çš„èµ‹å€¼
                                return True
                except:
                    continue
        return False

    # è¾…åŠ©æ–¹æ³•
    def _can_run_pytest(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦å¯ä»¥è¿è¡Œpytest"""
        try:
            subprocess.run(['pytest', '--version'], capture_output=True, timeout=5)
            return True
        except:
            return False

    def _extract_imports(self, tree: ast.AST) -> List[str]:
        """æå–å¯¼å…¥"""
        imports = []
        for node in ast.walk(tree):
            if isinstance(node, ast.Import):
                imports.extend([alias.name for alias in node.names])
            elif isinstance(node, ast.ImportFrom):
                module = node.module or ''
                imports.extend([f"{module}.{alias.name}" for alias in node.names])
        return list(set(imports))

    def _extract_module_dependencies(self, tree: ast.AST) -> List[str]:
        """æå–æ¨¡å—ä¾èµ–"""
        dependencies = []
        for node in ast.walk(tree):
            if isinstance(node, ast.Import):
                dependencies.extend([alias.name.split('.')[0] for alias in node.names])
            elif isinstance(node, ast.ImportFrom):
                if node.module:
                    dependencies.append(node.module.split('.')[0])
        return list(set(dependencies))

    def _calculate_complexity_score(self, tree: ast.AST) -> float:
        """è®¡ç®—å¤æ‚åº¦è¯„åˆ†"""
        def calculate_complexity(node):
            complexity = 1
            for child in ast.walk(node):
                if isinstance(child, (ast.If, ast.While, ast.For, ast.AsyncFor)):
                    complexity += 1
                elif isinstance(child, ast.ExceptHandler):
                    complexity += 1
                elif isinstance(child, ast.BoolOp):
                    complexity += len(child.values) - 1
            return complexity

        total_complexity = 0
        function_count = 0

        for node in ast.walk(tree):
            if isinstance(node, ast.FunctionDef):
                total_complexity += calculate_complexity(node)
                function_count += 1

        return total_complexity / max(function_count, 1)

    def _calculate_doc_coverage(self, tree: ast.AST) -> float:
        """è®¡ç®—æ–‡æ¡£è¦†ç›–ç‡"""
        documented = 0
        total = 0

        for node in ast.walk(tree):
            if isinstance(node, (ast.FunctionDef, ast.ClassDef)):
                total += 1
                if ast.get_docstring(node):
                    documented += 1

        return (documented / total * 100) if total > 0 else 0

    def _calculate_type_hints_coverage(self, tree: ast.AST) -> float:
        """è®¡ç®—ç±»å‹æç¤ºè¦†ç›–ç‡"""
        with_hints = 0
        total_functions = 0

        for node in ast.walk(tree):
            if isinstance(node, ast.FunctionDef):
                total_functions += 1
                if node.returns and all(arg.annotation for arg in node.args.args):
                    with_hints += 1

        return (with_hints / total_functions * 100) if total_functions > 0 else 0

    # å®‰å…¨æ£€æµ‹æ–¹æ³•
    def _has_hardcoded_secrets(self, content: str) -> bool:
        """æ£€æµ‹ç¡¬ç¼–ç å¯†é’¥"""
        secret_patterns = [
            r'api[_-]?key\s*=\s*[\'\"][^\'\"]{10,}[\'\"]',
            r'secret[_-]?key\s*=\s*[\'\"][^\'\"]{10,}[\'\"]',
            r'password\s*=\s*[\'\"][^\'\"]{8,}[\'\"]',
            r'token\s*=\s*[\'\"][^\'\"]{10,}[\'\"]'
        ]
        return any(re.search(pattern, content, re.IGNORECASE) for pattern in secret_patterns)

    def _has_sql_injection_risks(self, content: str) -> bool:
        """æ£€æµ‹SQLæ³¨å…¥é£é™©"""
        injection_patterns = [
            r'execute\s*\(\s*[\'\"]\s*.*%\s*.*[\'\"]',
            r'format.*sql',
            r'f\'[\'"]\s*.*\{.*\}.*\s*.*[\'\"].*sql'
        ]
        return any(re.search(pattern, content, re.IGNORECASE) for pattern in injection_patterns)

    def _has_dangerous_functions(self, content: str) -> bool:
        """æ£€æµ‹å±é™©å‡½æ•°"""
        dangerous_functions = ['eval(', 'exec(', 'compile(', '__import__(']
        return any(func in content for func in dangerous_functions)

    def _has_unsafe_pickle(self, content: str) -> bool:
        """æ£€æµ‹ä¸å®‰å…¨çš„pickleä½¿ç”¨"""
        return re.search(r'pickle\.load\s*\(', content, re.IGNORECASE) is not None

def generate_python_report(analysis: PythonArchitectureAnalysis) -> str:
    """ç”ŸæˆPythoné¡¹ç›®æ¶æ„åˆ†ææŠ¥å‘Š"""
    report = "# Pythoné¡¹ç›®æ¶æ„åˆ†ææŠ¥å‘Š\n\n"

    # é¡¹ç›®æ¦‚è§ˆ
    report += "## ğŸ“Š é¡¹ç›®æ¦‚è§ˆ\n"
    report += f"- **é¡¹ç›®ç±»å‹**: {analysis.project_type.value}\n"
    report += f"- **ä½¿ç”¨æ¡†æ¶**: {', '.join([f.value for f in analysis.frameworks]) if analysis.frameworks else 'æœªæ£€æµ‹åˆ°'}\n"
    report += f"- **è´¨é‡è¯„åˆ†**: {analysis.quality_score:.1f}/100\n"
    report += f"- **æ¶æ„æ¨¡å¼**: {len(analysis.patterns)} ä¸ª\n"
    report += f"- **è´¨é‡é—®é¢˜**: {len(analysis.quality_issues)} ä¸ª\n"
    report += f"- **æœ€ä½³å®è·µ**: {len(analysis.best_practices)} ä¸ª\n\n"

    # æ¡†æ¶åˆ†æ
    report += "## ğŸ”§ æ¡†æ¶åˆ†æ\n"
    if analysis.frameworks:
        for framework in analysis.frameworks:
            report += f"- âœ… **{framework.value}**: æ£€æµ‹åˆ°è¯¥æ¡†æ¶\n"
    else:
        report += "- âš ï¸ æœªæ£€æµ‹åˆ°æ˜ç¡®çš„æ¡†æ¶\n"
    report += "\n"

    # æ¶æ„æ¨¡å¼
    report += "## ğŸ—ï¸ æ¶æ„æ¨¡å¼è¯†åˆ«\n"
    if analysis.patterns:
        for pattern in analysis.patterns:
            report += f"- âœ… **{pattern.value}**: æ£€æµ‹åˆ°è¯¥æ¶æ„æ¨¡å¼\n"
    else:
        report += "- ğŸ’¡ å»ºè®®è€ƒè™‘åº”ç”¨è®¾è®¡æ¨¡å¼æé«˜ä»£ç è´¨é‡\n"
    report += "\n"

    # è´¨é‡é—®é¢˜
    report += "## âš ï¸ ä»£ç è´¨é‡é—®é¢˜\n"
    if analysis.quality_issues:
        for issue in analysis.quality_issues:
            report += f"- ğŸš¨ **{issue.value}**: éœ€è¦æ”¹è¿›\n"
    else:
        report += "- âœ… æœªæ£€æµ‹åˆ°æ˜æ˜¾çš„ä»£ç è´¨é‡é—®é¢˜\n"
    report += "\n"

    # æœ€ä½³å®è·µ
    report += "## ğŸ¯ æœ€ä½³å®è·µè¯„ä¼°\n"
    if analysis.best_practices:
        for practice in analysis.best_practices:
            report += f"- âœ¨ **{practice.value}**: è‰¯å¥½çš„å®è·µ\n"
    else:
        report += "- ğŸ’¡ å»ºè®®æ”¹è¿›å¼€å‘å®è·µ\n"
    report += "\n"

    # æ¨¡å—åˆ†æ
    report += "## ğŸ“¦ æ¨¡å—åˆ†æ\n"
    if analysis.modules:
        # æŒ‰å¤æ‚åº¦æ’åº
        sorted_modules = sorted(analysis.modules, key=lambda x: x.complexity_score, reverse=True)
        report += f"å…±åˆ†æäº† {len(analysis.modules)} ä¸ªæ¨¡å—\n\n"

        report += "### å¤æ‚åº¦è¾ƒé«˜çš„æ¨¡å—:\n"
        for module in sorted_modules[:5]:  # æ˜¾ç¤ºå‰5ä¸ªå¤æ‚åº¦è¾ƒé«˜çš„
            report += f"- **{module.name}**: å¤æ‚åº¦ {module.complexity_score:.1f}, {module.lines_of_code}è¡Œ\n"
            report += f"  ğŸ“ `{module.file_path}`\n"
            report += f"  ğŸ“‹ å‡½æ•°: {len(module.functions)}, ç±»: {len(module.classes)}\n"

        report += "\n### é«˜è´¨é‡æ¨¡å—:\n"
        for module in sorted_modules[-3:]:  # æ˜¾ç¤ºæœ€å3ä¸ªè´¨é‡è¾ƒé«˜çš„
            report += f"- **{module.name}**: æ–‡æ¡£è¦†ç›–ç‡ {module.documentation_coverage:.1f}%, ç±»å‹æç¤ºè¦†ç›–ç‡ {module.type_hints_coverage:.1f}%\n"
    report += "\n"

    # ä¾èµ–åˆ†æ
    report += "## ğŸ“‹ ä¾èµ–åˆ†æ\n"
    if analysis.dependencies:
        report += f"å…±å‘ç° {len(analysis.dependencies)} ä¸ªä¾èµ–åŒ…\n\n"
        for dep, version in list(analysis.dependencies.items())[:10]:  # æ˜¾ç¤ºå‰10ä¸ª
            report += f"- **{dep}**: {version}\n"
        if len(analysis.dependencies) > 10:
            report += f"- ... è¿˜æœ‰ {len(analysis.dependencies) - 10} ä¸ªä¾èµ–\n"
    else:
        report += "- âš ï¸ æœªæ‰¾åˆ°ä¾èµ–é…ç½®æ–‡ä»¶\n"
    report += "\n"

    # æµ‹è¯•è¦†ç›–ç‡
    report += "## ğŸ§ª æµ‹è¯•è¦†ç›–ç‡\n"
    if analysis.test_coverage:
        if 'overall' in analysis.test_coverage:
            report += f"- **æ•´ä½“è¦†ç›–ç‡**: {analysis.test_coverage['overall']:.1f}%\n"
        if 'test_to_source_ratio' in analysis.test_coverage:
            report += f"- **æµ‹è¯•/æºç æ¯”ä¾‹**: {analysis.test_coverage['test_to_source_ratio']:.2f}\n"
    else:
        report += "- âš ï¸ æ— æ³•è·å–æµ‹è¯•è¦†ç›–ç‡ä¿¡æ¯\n"
    report += "\n"

    # å®‰å…¨é—®é¢˜
    report += "## ğŸ”’ å®‰å…¨åˆ†æ\n"
    if analysis.security_issues:
        for issue in analysis.security_issues:
            report += f"- ğŸš¨ {issue}\n"
    else:
        report += "- âœ… æœªæ£€æµ‹åˆ°æ˜æ˜¾çš„å®‰å…¨é—®é¢˜\n"
    report += "\n"

    # é¡¹ç›®ç»“æ„
    report += "## ğŸ“ é¡¹ç›®ç»“æ„åˆ†æ\n"
    for category, files in analysis.project_structure.items():
        if files:
            report += f"- **{category}**: {len(files)} ä¸ªæ–‡ä»¶\n"
    report += "\n"

    # æ”¹è¿›å»ºè®®
    report += "## ğŸ’¡ æ”¹è¿›å»ºè®®\n"
    for i, suggestion in enumerate(analysis.recommendations, 1):
        report += f"{i}. {suggestion}\n"
    report += "\n"

    # è´¨é‡è¯„ä¼°
    report += "## ğŸ“ˆ è´¨é‡è¯„ä¼°\n"
    if analysis.quality_score >= 80:
        report += "ğŸŸ¢ **ä¼˜ç§€**: é¡¹ç›®æ¶æ„å’Œä»£ç è´¨é‡å¾ˆé«˜\n"
    elif analysis.quality_score >= 60:
        report += "ğŸŸ¡ **è‰¯å¥½**: é¡¹ç›®æ•´ä½“è´¨é‡ä¸é”™ï¼Œæœ‰æ”¹è¿›ç©ºé—´\n"
    elif analysis.quality_score >= 40:
        report += "ğŸŸ  **ä¸€èˆ¬**: å­˜åœ¨ä¸€äº›é—®é¢˜ï¼Œéœ€è¦é‡ç‚¹å…³æ³¨\n"
    else:
        report += "ğŸ”´ **éœ€è¦æ”¹è¿›**: å­˜åœ¨è¾ƒå¤šé—®é¢˜ï¼Œå»ºè®®è¿›è¡Œé‡æ„\n"
    report += "\n"

    return report

if __name__ == "__main__":
    import sys
    if len(sys.argv) != 2:
        print("ç”¨æ³•: python python_analyzer.py <Pythoné¡¹ç›®è·¯å¾„>")
        sys.exit(1)

    project_path = Path(sys.argv[1])
    analyzer = PythonArchitectureAnalyzer(project_path)
    analysis = analyzer.analyze()
    report = generate_python_report(analysis)

    print(report)

    # ä¿å­˜æŠ¥å‘Š
    output_file = project_path / "python_architecture_analysis.md"
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(report)

    print(f"\nğŸ“„ æŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_file}")