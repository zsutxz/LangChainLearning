# RAGç³»ç»Ÿ - æ™ºèƒ½æ£€ç´¢å¢å¼ºç”Ÿæˆç³»ç»Ÿ

ä¸€ä¸ªæ¨¡å—åŒ–ã€é«˜æ€§èƒ½çš„RAGï¼ˆRetrieval-Augmented Generationï¼‰ç³»ç»Ÿï¼Œæ”¯æŒå¤šç§å‘é‡æ•°æ®åº“å’ŒåµŒå…¥æ¨¡å‹ï¼Œä¸“ä¸ºç”Ÿäº§ç¯å¢ƒè®¾è®¡ã€‚

## ğŸŒŸ æ ¸å¿ƒç‰¹æ€§

### ğŸ”§ å®Œæ•´RAGæµç¨‹
- **æ™ºèƒ½æ£€ç´¢**ï¼šåŸºäºç›¸ä¼¼åº¦çš„æ–‡æ¡£æ£€ç´¢
- **ç­”æ¡ˆç”Ÿæˆ**ï¼šé›†æˆDeepSeek LLMç”Ÿæˆæ™ºèƒ½ç­”æ¡ˆ
- **æ— ç¼é›†æˆ**ï¼šæ£€ç´¢å’Œç”Ÿæˆçš„å®Œç¾ç»“åˆ

### ğŸ§© æ¨¡å—åŒ–æ¶æ„
- **æ ¸å¿ƒè§£è€¦**ï¼šå„ç»„ä»¶ç‹¬ç«‹ï¼Œæ˜“äºæ‰©å±•å’Œç»´æŠ¤
- **æ’ä»¶åŒ–è®¾è®¡**ï¼šæ”¯æŒè‡ªå®šä¹‰åµŒå…¥æ¨¡å‹å’Œå‘é‡å­˜å‚¨
- **çµæ´»é…ç½®**ï¼šé€‚åº”ä¸åŒåœºæ™¯çš„éœ€æ±‚

### ğŸš€ å¤šæ¨¡å‹æ”¯æŒ
- **åµŒå…¥æ¨¡å‹**ï¼šSentence-Transformersã€OpenAIã€Hugging Face
- **å‘é‡æ•°æ®åº“**ï¼šChromaã€FAISSã€Pineconeã€Weaviateã€Qdrant
- **LLMé›†æˆ**ï¼šDeepSeekã€OpenAIã€Anthropic Claude

### ğŸ›¡ï¸ ä¼ä¸šçº§ç‰¹æ€§
- **æœ¬åœ°éƒ¨ç½²**ï¼šæ”¯æŒå®Œå…¨ç¦»çº¿è¿è¡Œï¼Œä¿æŠ¤æ•°æ®éšç§
- **é«˜æ€§èƒ½**ï¼šæ‰¹é‡å¤„ç†ã€GPUåŠ é€Ÿã€ç¼“å­˜æœºåˆ¶
- **æ˜“äºæ‰©å±•**ï¼šæ”¯æŒè‡ªå®šä¹‰ç»„ä»¶å’Œæ‰©å±•

## ğŸ“ é¡¹ç›®ç»“æ„

```
rag/
â”œâ”€â”€ core/                           # æ ¸å¿ƒRAGæ¨¡å—
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ document_loader.py          # æ–‡æ¡£åŠ è½½å™¨
â”‚   â”œâ”€â”€ vector_store.py             # å‘é‡å­˜å‚¨ç®¡ç†
â”‚   â””â”€â”€ rag_system.py               # å®Œæ•´RAGç³»ç»Ÿå®ç°
â”œâ”€â”€ embeddings/                     # åµŒå…¥æ¨¡å‹
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ sentence_transformers_embeddings.py  # Sentence-Transformerså®ç°
â”œâ”€â”€ llm/                            # LLMé›†æˆæ¨¡å—
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base_llm.py                 # LLMåŸºç±»
â”‚   â””â”€â”€ deepseek_llm.py             # DeepSeek LLMå®ç°
â”œâ”€â”€ config/                         # é…ç½®ç®¡ç†
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ environment.py              # ç¯å¢ƒé…ç½®
â”‚   â””â”€â”€ huggingface_mirror.py       # HuggingFaceé•œåƒé…ç½®
â”œâ”€â”€ utils/                          # å·¥å…·æ¨¡å—
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ similarity.py               # ç›¸ä¼¼åº¦è®¡ç®—
â”œâ”€â”€ tests/                          # æµ‹è¯•æ¨¡å—
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ test_sentence_transformers.py
â”œâ”€â”€ data/                           # æ•°æ®ç›®å½•
â”‚   â””â”€â”€ sample_documents/           # ç¤ºä¾‹æ–‡æ¡£
â”‚       â””â”€â”€ rag_introduction.md
â”œâ”€â”€ main.py                         # ä¸»ç¨‹åºå…¥å£
â”œâ”€â”€ demo_rag.py                     # RAGç³»ç»Ÿæ¼”ç¤ºè„šæœ¬
â”œâ”€â”€ .env.example                    # ç¯å¢ƒå˜é‡ç¤ºä¾‹
â”œâ”€â”€ requirements.txt                # ä¾èµ–åˆ—è¡¨
â””â”€â”€ README.md                       # é¡¹ç›®æ–‡æ¡£
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒå‡†å¤‡

```bash
# å…‹éš†é¡¹ç›®
git clone <repository-url>
cd rag

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# å®‰è£…ä¾èµ–
pip install -r requirements.txt
```

### 2. é…ç½®ç¯å¢ƒå˜é‡

åˆ›å»º `.env` æ–‡ä»¶ï¼š

```env
# Hugging Faceé•œåƒï¼ˆå›½å†…ç”¨æˆ·æ¨èï¼‰
HF_ENDPOINT=https://hf-mirror.com

# DeepSeek APIï¼ˆç”¨äºç­”æ¡ˆç”Ÿæˆï¼‰
DEEPSEEK_API_KEY=your_deepseek_api_key_here

# OpenAI APIï¼ˆå¯é€‰ï¼‰
OPENAI_API_KEY=your_openai_api_key_here

# å…¶ä»–é…ç½®...
```

### 3. è¿è¡Œç¤ºä¾‹

```bash
# è¿è¡Œå®Œæ•´RAGç³»ç»Ÿæµ‹è¯•
python main.py

# è¿è¡Œäº¤äº’å¼æ¼”ç¤º
python demo_rag.py

# ä»…è¿è¡Œæ£€ç´¢éƒ¨åˆ†æµ‹è¯•
python main.py --mode retrieval

# è¿è¡Œå®Œæ•´åŠŸèƒ½
python main.py --mode complete
```

## ğŸ’» ä½¿ç”¨ç¤ºä¾‹

### åŸºç¡€RAGç³»ç»Ÿä½¿ç”¨

```python
from core.rag_system import CompleteRAGSystem, RAGConfig
from embeddings.sentence_transformers_embeddings import SentenceTransformersEmbeddings
from config.environment import setup_environment

# 1. åˆ›å»ºRAGé…ç½®
config = RAGConfig(
    model_name="shibing624/text2vec-base-chinese",
    vector_store_type="chroma",
    llm_provider="deepseek",
    chunk_size=1000,
    chunk_overlap=200
)

# 2. åˆå§‹åŒ–RAGç³»ç»Ÿ
rag_system = CompleteRAGSystem(config)

# 3. æ·»åŠ æ–‡æ¡£
documents = ["ä½ çš„æ–‡æ¡£å†…å®¹1", "ä½ çš„æ–‡æ¡£å†…å®¹2"]
rag_system.add_documents(documents)

# 4. æŸ¥è¯¢å¹¶ç”Ÿæˆç­”æ¡ˆ
query = "ä»€ä¹ˆæ˜¯RAGæŠ€æœ¯ï¼Ÿ"
response = rag_system.query(query)
print(f"å›ç­”: {response['answer']}")
print(f"æ¥æº: {response['source_documents']}")
```

### ç‹¬ç«‹ä½¿ç”¨æ£€ç´¢åŠŸèƒ½

```python
from embeddings.sentence_transformers_embeddings import SentenceTransformersEmbeddings
from core.document_loader import DocumentLoader
from core.vector_store import VectorStoreManager

# åˆå§‹åŒ–åµŒå…¥æ¨¡å‹
embeddings = SentenceTransformersEmbeddings(
    model_name="paraphrase-multilingual-MiniLM-L12-v2"
)

# åŠ è½½æ–‡æ¡£
loader = DocumentLoader()
documents = loader.load_text_documents()

# åˆ›å»ºå‘é‡å­˜å‚¨
vector_store_manager = VectorStoreManager()
vector_store = vector_store_manager.create_vector_store(
    documents=documents,
    embeddings=embeddings
)

# æ‰§è¡Œæœç´¢
query = "ä»€ä¹ˆæ˜¯RAGæŠ€æœ¯ï¼Ÿ"
results = vector_store_manager.similarity_search(query, k=3)
vector_store_manager.print_search_results(results)
```

### é«˜çº§ç”¨æ³•

```python
# æ‰¹é‡åµŒå…¥ä¼˜åŒ–
batch_results = embeddings.test_batch_embedding(
    texts=["æ–‡æœ¬1", "æ–‡æœ¬2", "æ–‡æœ¬3"],
    batch_size=32
)

# ç›¸ä¼¼åº¦åˆ†æ
from utils.similarity import SimilarityCalculator

text1_emb = embeddings.embed_query("äººå·¥æ™ºèƒ½æ­£åœ¨æ”¹å˜ä¸–ç•Œ")
text2_emb = embeddings.embed_query("AIæŠ€æœ¯å½±å“æˆ‘ä»¬çš„ç”Ÿæ´»")
similarity = SimilarityCalculator.cosine_similarity(text1_emb, text2_emb)
print(f"ç›¸ä¼¼åº¦: {similarity:.3f}")
```

## ğŸ”§ é…ç½®é€‰é¡¹

### åµŒå…¥æ¨¡å‹é€‰æ‹©

| æ¨¡å‹åç§° | å¤§å° | è¯­è¨€ | ç‰¹ç‚¹ | é€‚ç”¨åœºæ™¯ |
|---------|------|------|------|---------|
| `shibing624/text2vec-base-chinese` | 420MB | ä¸­æ–‡ | ä¸­æ–‡ä¼˜åŒ– | ä¸­æ–‡åº”ç”¨ |
| `paraphrase-multilingual-MiniLM-L12-v2` | 420MB | å¤šè¯­è¨€ | è½»é‡å¤šè¯­è¨€ | å›½é™…åŒ–åº”ç”¨ |
| `all-mpnet-base-v2` | 420MB | è‹±æ–‡ | é«˜è´¨é‡è‹±æ–‡ | è‹±æ–‡åº”ç”¨ |
| `paraphrase-multilingual-mpnet-base-v2` | 1.1GB | å¤šè¯­è¨€ | é«˜è´¨é‡å¤šè¯­è¨€ | é«˜è´¨é‡è¦æ±‚ |

### å‘é‡æ•°æ®åº“é…ç½®

```python
# Chromaï¼ˆé»˜è®¤ï¼Œè½»é‡çº§æœ¬åœ°ï¼‰
vector_store = VectorStoreManager().create_vector_store(
    documents=documents,
    embeddings=embeddings,
    vector_store_type="chroma"
)

# FAISSï¼ˆé«˜æ€§èƒ½æœ¬åœ°ï¼‰
vector_store = VectorStoreManager().create_vector_store(
    documents=documents,
    embeddings=embeddings,
    vector_store_type="faiss"
)

# Pineconeï¼ˆäº‘ç«¯æ‰˜ç®¡ï¼‰
vector_store = VectorStoreManager().create_vector_store(
    documents=documents,
    embeddings=embeddings,
    vector_store_type="pinecone"
)
```

### LLMé…ç½®

```python
# DeepSeekï¼ˆæ¨èï¼Œé«˜æ€§ä»·æ¯”ï¼‰
config = RAGConfig(
    llm_provider="deepseek",
    model="deepseek-chat"
)

# OpenAI
config = RAGConfig(
    llm_provider="openai",
    model="gpt-3.5-turbo"
)
```

## ğŸ“Š æ€§èƒ½ä¼˜åŒ–

### 1. æ‰¹é‡å¤„ç†

```python
# æ‰¹é‡åµŒå…¥ï¼Œæé«˜æ•ˆç‡
embeddings_list = embeddings.embed_documents(
    texts=large_text_list,
    batch_size=32
)
```

### 2. GPUåŠ é€Ÿ

```python
# è‡ªåŠ¨æ£€æµ‹å¹¶ä½¿ç”¨GPU
import torch
device = 'cuda' if torch.cuda.is_available() else 'cpu'
model = SentenceTransformer(model_name).to(device)
```

### 3. ç¼“å­˜æœºåˆ¶

```python
# åµŒå…¥ç»“æœè‡ªåŠ¨ç¼“å­˜
embeddings = SentenceTransformersEmbeddings(
    model_name=model_name,
    cache_folder="./embeddings_cache"
)
```

### 4. åˆ†å—ä¼˜åŒ–

```python
# ä¼˜åŒ–æ–‡æ¡£åˆ†å—ç­–ç•¥
config = RAGConfig(
    chunk_size=1000,
    chunk_overlap=200,
    separators=["\n\n", "\n", " ", ""]
)
```

## ğŸŒ ç½‘ç»œé—®é¢˜è§£å†³

### å›½å†…ç”¨æˆ·ä¼˜åŒ–

```python
# è‡ªåŠ¨é…ç½®HuggingFaceé•œåƒ
from config.huggingface_mirror import setup_huggingface_mirror
setup_huggingface_mirror()
```

### ç¦»çº¿éƒ¨ç½²

1. ä¸‹è½½æ¨¡å‹åˆ°æœ¬åœ°ç›®å½•
2. é…ç½®æœ¬åœ°æ¨¡å‹è·¯å¾„
3. å®Œå…¨ç¦»çº¿è¿è¡Œ

```python
embeddings = SentenceTransformersEmbeddings(
    model_name="/path/to/local/model"
)
```

## ğŸ§ª æµ‹è¯•

```bash
# è¿è¡Œæ‰€æœ‰æµ‹è¯•
python -m pytest tests/

# è¿è¡Œç‰¹å®šæµ‹è¯•
python -m pytest tests/test_sentence_transformers.py

# è¿è¡Œæ€§èƒ½æµ‹è¯•
python tests/test_sentence_transformers.py --benchmark

# è¿è¡ŒRAGç³»ç»Ÿå®Œæ•´æµ‹è¯•
python main.py --mode complete
```

## ğŸ“š APIæ–‡æ¡£

### SentenceTransformersEmbeddings

ä¸»è¦çš„åµŒå…¥æ¨¡å‹ç±»ï¼Œæä¾›æ–‡æœ¬åµŒå…¥åŠŸèƒ½ã€‚

#### æ–¹æ³•åˆ—è¡¨

- `embed_query(text: str) -> np.ndarray`: ç”ŸæˆæŸ¥è¯¢åµŒå…¥
- `embed_documents(texts: List[str]) -> List[np.ndarray]`: æ‰¹é‡ç”Ÿæˆæ–‡æ¡£åµŒå…¥
- `test_embedding(text: str) -> Dict`: æµ‹è¯•å•ä¸ªæ–‡æœ¬åµŒå…¥
- `test_batch_embedding() -> Dict`: æµ‹è¯•æ‰¹é‡åµŒå…¥æ€§èƒ½

### CompleteRAGSystem

å®Œæ•´çš„RAGç³»ç»Ÿå®ç°ï¼Œé›†æˆæ£€ç´¢å’Œç”Ÿæˆã€‚

#### æ–¹æ³•åˆ—è¡¨

- `add_documents(documents: List[str])`: æ·»åŠ æ–‡æ¡£åˆ°ç³»ç»Ÿ
- `query(question: str) -> Dict`: æ‰§è¡ŒRAGæŸ¥è¯¢
- `search_documents(query: str, k: int = 4)`: æ£€ç´¢ç›¸å…³æ–‡æ¡£
- `clear_documents()`: æ¸…ç©ºæ‰€æœ‰æ–‡æ¡£

### VectorStoreManager

å‘é‡å­˜å‚¨ç®¡ç†å™¨ï¼Œæ”¯æŒå¤šç§å‘é‡æ•°æ®åº“ã€‚

#### æ–¹æ³•åˆ—è¡¨

- `create_vector_store(documents, embeddings)`: åˆ›å»ºå‘é‡å­˜å‚¨
- `similarity_search(query: str, k: int = 4)`: æ‰§è¡Œç›¸ä¼¼åº¦æœç´¢
- `print_search_results(results)`: æ ¼å¼åŒ–æ‰“å°æœç´¢ç»“æœ

### DocumentLoader

æ–‡æ¡£åŠ è½½å™¨ï¼Œæ”¯æŒå¤šç§æ–‡æ¡£æ ¼å¼ã€‚

#### æ–¹æ³•åˆ—è¡¨

- `load_text_documents(directory: str = "./data")`: åŠ è½½æ–‡æœ¬æ–‡æ¡£
- `create_test_documents()`: åˆ›å»ºæµ‹è¯•æ–‡æ¡£
- `load_pdf_documents(file_path: str)`: åŠ è½½PDFæ–‡æ¡£

## ğŸ” æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **æ¨¡å‹ä¸‹è½½å¤±è´¥**
   - æ£€æŸ¥ç½‘ç»œè¿æ¥
   - ä½¿ç”¨å›½å†…é•œåƒï¼š`HF_ENDPOINT=https://hf-mirror.com`
   - æ‰‹åŠ¨ä¸‹è½½æ¨¡å‹æ–‡ä»¶

2. **å†…å­˜ä¸è¶³**
   - ä½¿ç”¨æ›´å°çš„æ¨¡å‹
   - å‡å°batch_size
   - ä½¿ç”¨CPUè€ŒéGPU

3. **æ€§èƒ½é—®é¢˜**
   - å¯ç”¨GPUåŠ é€Ÿ
   - ä½¿ç”¨æ‰¹é‡å¤„ç†
   - å®ç°ç¼“å­˜æœºåˆ¶

4. **ä¸­æ–‡æ”¯æŒ**
   - ä½¿ç”¨ä¸­æ–‡ä¼˜åŒ–æ¨¡å‹ï¼š`shibing624/text2vec-base-chinese`
   - ç¡®ä¿æ–‡æœ¬ç¼–ç æ­£ç¡®

5. **APIå¯†é’¥é”™è¯¯**
   - æ£€æŸ¥.envæ–‡ä»¶é…ç½®
   - éªŒè¯APIå¯†é’¥æœ‰æ•ˆæ€§

### è°ƒè¯•æ¨¡å¼

```python
import logging
logging.basicConfig(level=logging.DEBUG)

# å¯ç”¨è¯¦ç»†æ—¥å¿—
import os
os.environ["TRANSFORMERS_VERBOSITY"] = "detailed"
```

## ğŸ¯ æœ€ä½³å®è·µ

### 1. æ–‡æ¡£é¢„å¤„ç†

```python
# æ¸…ç†å’Œé¢„å¤„ç†æ–‡æ¡£
documents = [
    doc.strip() for doc in documents
    if len(doc.strip()) > 50  # è¿‡æ»¤å¤ªçŸ­çš„æ–‡æ¡£
]
```

### 2. æŸ¥è¯¢ä¼˜åŒ–

```python
# æŸ¥è¯¢æ‰©å±•å’Œé‡å†™
expanded_query = f"{query} ç›¸å…³æ¦‚å¿µ å®é™…åº”ç”¨"
response = rag_system.query(expanded_query)
```

### 3. ç»“æœåå¤„ç†

```python
# å¯¹ç­”æ¡ˆè¿›è¡Œåå¤„ç†
answer = response['answer']
if len(answer) > 500:
    # æˆªæ–­è¿‡é•¿çš„ç­”æ¡ˆ
    answer = answer[:500] + "..."
```

## ğŸ¤ è´¡çŒ®æŒ‡å—

1. Fork é¡¹ç›®
2. åˆ›å»ºç‰¹æ€§åˆ†æ”¯ (`git checkout -b feature/AmazingFeature`)
3. æäº¤æ›´æ”¹ (`git commit -m 'Add some AmazingFeature'`)
4. æ¨é€åˆ°åˆ†æ”¯ (`git push origin feature/AmazingFeature`)
5. å¼€å¯ Pull Request

### å¼€å‘è§„èŒƒ

- éµå¾ªPEP 8ä»£ç é£æ ¼
- æ·»åŠ é€‚å½“çš„æ–‡æ¡£å­—ç¬¦ä¸²
- ç¼–å†™å•å…ƒæµ‹è¯•
- æ›´æ–°ç›¸å…³æ–‡æ¡£

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ - æŸ¥çœ‹ [LICENSE](LICENSE) æ–‡ä»¶äº†è§£è¯¦æƒ…ã€‚

## ğŸ™ è‡´è°¢

- [Sentence-Transformers](https://github.com/UKPLab/sentence-transformers) - ä¼˜ç§€çš„å¥å­åµŒå…¥åº“
- [LangChain](https://github.com/langchain-ai/langchain) - å¼ºå¤§çš„LLMåº”ç”¨æ¡†æ¶
- [ChromaDB](https://github.com/chroma-core/chroma) - è½»é‡çº§å‘é‡æ•°æ®åº“
- [FAISS](https://github.com/facebookresearch/faiss) - é«˜æ•ˆçš„ç›¸ä¼¼åº¦æœç´¢åº“
- [DeepSeek](https://github.com/deepseek-ai) - é«˜æ€§èƒ½å¤§è¯­è¨€æ¨¡å‹

## ğŸ“ è”ç³»æ–¹å¼

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·é€šè¿‡ä»¥ä¸‹æ–¹å¼è”ç³»ï¼š

- æäº¤ [Issue](https://github.com/your-username/rag/issues)
- å‘é€é‚®ä»¶è‡³ your-email@example.com
- æŸ¥çœ‹ [Wiki](https://github.com/your-username/ag/wiki) è·å–æ›´å¤šæ–‡æ¡£

---

**æ³¨æ„**ï¼šæœ¬ç³»ç»Ÿä»åœ¨å¼€å‘ä¸­ï¼ŒæŸäº›åŠŸèƒ½å¯èƒ½å‘ç”Ÿå˜åŒ–ã€‚å»ºè®®åœ¨ç”Ÿäº§ç¯å¢ƒä½¿ç”¨å‰è¿›è¡Œå……åˆ†æµ‹è¯•ã€‚

**æ›´æ–°æ—¥å¿—**ï¼š
- v1.0.0 - åˆå§‹ç‰ˆæœ¬ï¼Œæ”¯æŒåŸºç¡€RAGåŠŸèƒ½
- v1.1.0 - æ·»åŠ DeepSeek LLMæ”¯æŒ
- v1.2.0 - ä¼˜åŒ–æ€§èƒ½ï¼Œæ·»åŠ æ‰¹é‡å¤„ç†
- v1.3.0 - å¢åŠ å¤šå‘é‡æ•°æ®åº“æ”¯æŒ