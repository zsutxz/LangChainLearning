{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20299de2-ec98-4767-a92e-fe93f93b86dc",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install -U langchain\n",
    "!pip install langchain langchain-community langchain-core\n",
    "!pip install langchain-openai openai\n",
    "!pip install langchain-deepseek\n",
    "!pip install deepseek-api python-dotenv\n",
    "\n",
    "# Installing the OpenAI integration\n",
    "#!pip install -U langchain-openai\n",
    "# Installing the Anthropic integration\n",
    "# !pip install -U langchain-anthropic\n",
    "\n",
    "!pip show langchain-core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f76dc057-7bf5-4c26-941c-d05a9f334cc3",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2025-10-28T12:10:22.713886Z",
     "iopub.status.busy": "2025-10-28T12:10:22.713670Z",
     "iopub.status.idle": "2025-10-28T12:10:26.131036Z",
     "shell.execute_reply": "2025-10-28T12:10:26.130541Z",
     "shell.execute_reply.started": "2025-10-28T12:10:22.713867Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.tools import tool, ToolRuntime\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "\n",
    "# è®¾ç½® DeepSeek çš„ API å¯†é’¥ï¼ˆLangChain-OpenAI ä»ç„¶ä¼šæŸ¥æ‰¾ OPENAI_API_KEYï¼‰\n",
    "# æ‚¨å¯ä»¥å°è¯•å°† DEEPSEEK_API_KEY çš„å€¼èµ‹ç»™ OPENAI_API_KEY çŽ¯å¢ƒå˜é‡\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.environ.get(\"DEEPSEEK_API_KEY\", \"your_deepseek_api_key_here\") # ç¡®ä¿è¿™ä¸ªå€¼æ˜¯ DeepSeek çš„ key\n",
    "\n",
    "# å…³é”®ï¼šæŒ‡å®š DeepSeek çš„ API åŸºç¡€ URL\n",
    "DEEPSEEK_BASE_URL = \"https://api.deepseek.com/v1\"\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    model=\"deepseek-chat\", # ä½¿ç”¨ DeepSeek çš„æ¨¡åž‹åç§°\n",
    "    openai_api_base=DEEPSEEK_BASE_URL, # æŒ‡å®š DeepSeek çš„ URL\n",
    "    temperature=0.7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4908f9c8-6e8c-4c81-9a5a-a11bf7fdd81c",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2025-10-28T12:10:28.946850Z",
     "iopub.status.busy": "2025-10-28T12:10:28.946458Z",
     "iopub.status.idle": "2025-10-28T12:10:31.398196Z",
     "shell.execute_reply": "2025-10-28T12:10:31.397765Z",
     "shell.execute_reply.started": "2025-10-28T12:10:28.946827Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Hello', additional_kwargs={}, response_metadata={}, id='d6d3141c-de65-4bd6-a48f-a00062971ed4'),\n",
       "  AIMessage(content='Hello! How can I help you today? I have access to tools that can look up and save user information if you need assistance with that.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 29, 'prompt_tokens': 208, 'total_tokens': 237, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 192}, 'prompt_cache_hit_tokens': 192, 'prompt_cache_miss_tokens': 16}, 'model_provider': 'openai', 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_ffc7281d48_prod0820_fp8_kvcache', 'id': 'ae19aec2-de7f-45b5-a3e7-108f3d7bfeb1', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--17bfce14-451b-41f7-a596-498860350f66-0', usage_metadata={'input_tokens': 208, 'output_tokens': 29, 'total_tokens': 237, 'input_token_details': {'cache_read': 192}, 'output_token_details': {}})],\n",
       " 'user_id': 'user_123',\n",
       " 'preferences': {'theme': 'dark'}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from typing import Any\n",
    "from langchain.agents import create_agent, AgentState\n",
    "from langgraph.checkpoint.memory import InMemorySaver \n",
    "from langchain.tools import tool, ToolRuntime\n",
    "\n",
    "# Access memory\n",
    "@tool\n",
    "def get_user_info(user_id: str, runtime: ToolRuntime) -> str:\n",
    "    \"\"\"Look up user info.\"\"\"\n",
    "    store = runtime.store\n",
    "    user_info = store.get((\"users\",), user_id)\n",
    "    return str(user_info.value) if user_info else \"Unknown user\"\n",
    "\n",
    "# Update memory\n",
    "@tool\n",
    "def save_user_info(user_id: str, user_info: dict[str, Any], runtime: ToolRuntime) -> str:\n",
    "    \"\"\"Save user info.\"\"\"\n",
    "    store = runtime.store\n",
    "    store.put((\"users\",), user_id, user_info)\n",
    "    return \"Successfully saved user info.\"\n",
    "\n",
    "class CustomAgentState(AgentState):  \n",
    "    user_id: str\n",
    "    preferences: dict\n",
    "\n",
    "agent = create_agent(\n",
    "    model,\n",
    "    tools=[get_user_info, save_user_info],\n",
    "    state_schema=CustomAgentState,\n",
    "    checkpointer=InMemorySaver(),\n",
    ")\n",
    "\n",
    "# Custom state can be passed in invoke\n",
    "result = agent.invoke(\n",
    "    {\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": \"Hello\"}],\n",
    "        \"user_id\": \"user_123\",  \n",
    "        \"preferences\": {\"theme\": \"dark\"}  \n",
    "    },\n",
    "    {\"configurable\": {\"thread_id\": \"1\"}})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca42ab8f-f5d3-47b5-bb0a-94f5bfd6cbd6",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2025-10-28T12:10:35.575093Z",
     "iopub.status.busy": "2025-10-28T12:10:35.574850Z",
     "iopub.status.idle": "2025-10-28T12:10:48.668282Z",
     "shell.execute_reply": "2025-10-28T12:10:48.667878Z",
     "shell.execute_reply.started": "2025-10-28T12:10:35.575076Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Your name is **Bob**! It's a pleasure to talk with you.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n================================== Ai Message ==================================\\n\\nYour name is Bob. You told me that earlier.\\nIf you'd like me to call you a nickname or use a different name, just say the word.\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.messages import RemoveMessage\n",
    "from langgraph.graph.message import REMOVE_ALL_MESSAGES\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain.agents import create_agent, AgentState\n",
    "from langchain.agents.middleware import before_model\n",
    "from langgraph.runtime import Runtime\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from typing import Any\n",
    "\n",
    "\n",
    "@before_model\n",
    "def trim_messages(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
    "    \"\"\"Keep only the last few messages to fit context window.\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "    if len(messages) <= 3:\n",
    "        return None  # No changes needed\n",
    "\n",
    "    first_msg = messages[0]\n",
    "    recent_messages = messages[-3:] if len(messages) % 2 == 0 else messages[-4:]\n",
    "    new_messages = [first_msg] + recent_messages\n",
    "\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            RemoveMessage(id=REMOVE_ALL_MESSAGES),\n",
    "            *new_messages\n",
    "        ]\n",
    "    }\n",
    "\n",
    "agent = create_agent(\n",
    "    model,\n",
    "    # tools=tools,\n",
    "    middleware=[trim_messages],\n",
    "    checkpointer=InMemorySaver(),\n",
    ")\n",
    "\n",
    "config: RunnableConfig = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "agent.invoke({\"messages\": \"hi, my name is bob\"}, config)\n",
    "agent.invoke({\"messages\": \"write a short poem about cats\"}, config)\n",
    "agent.invoke({\"messages\": \"now do the same but for dogs\"}, config)\n",
    "final_response = agent.invoke({\"messages\": \"what's my name?\"}, config)\n",
    "\n",
    "final_response[\"messages\"][-1].pretty_print()\n",
    "\"\"\"\n",
    "================================== Ai Message ==================================\n",
    "\n",
    "Your name is Bob. You told me that earlier.\n",
    "If you'd like me to call you a nickname or use a different name, just say the word.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1844029b-6464-476b-bdab-22a6bfd6ab0a",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2025-10-28T03:28:10.474107Z",
     "iopub.status.busy": "2025-10-28T03:28:10.473788Z",
     "iopub.status.idle": "2025-10-28T03:28:13.766303Z",
     "shell.execute_reply": "2025-10-28T03:28:13.765665Z",
     "shell.execute_reply.started": "2025-10-28T03:28:10.474088Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('human', \"hi! I'm bob\")]\n",
      "[('human', \"hi! I'm bob\"), ('ai', 'Hi Bob! Nice to meet you. How can I help you today?')]\n",
      "[('human', \"hi! I'm bob\"), ('ai', 'Hi Bob! Nice to meet you. How can I help you today?'), ('human', \"what's my name?\")]\n",
      "[('human', \"hi! I'm bob\"), ('ai', 'Hi Bob! Nice to meet you. How can I help you today?'), ('human', \"what's my name?\"), ('ai', 'Your name is Bob! ðŸ˜Š')]\n",
      "[('human', \"what's my name?\"), ('ai', 'Your name is Bob! ðŸ˜Š')]\n"
     ]
    }
   ],
   "source": [
    "from langchain.messages import RemoveMessage  \n",
    "from langgraph.graph.message import REMOVE_ALL_MESSAGES\n",
    "\n",
    "def delete_messages(state):\n",
    "    messages = state[\"messages\"]\n",
    "    if len(messages) > 2:\n",
    "        # remove the earliest two messages\n",
    "        return {\"messages\": [RemoveMessage(id=m.id) for m in messages[:2]]}\n",
    "\n",
    "def delete_messages(state):\n",
    "    return {\"messages\": [RemoveMessage(id=REMOVE_ALL_MESSAGES)]}\n",
    "\n",
    "from langchain.messages import RemoveMessage\n",
    "from langchain.agents import create_agent, AgentState\n",
    "from langchain.agents.middleware import after_model\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langgraph.runtime import Runtime\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "\n",
    "@after_model\n",
    "def delete_old_messages(state: AgentState, runtime: Runtime) -> dict | None:\n",
    "    \"\"\"Remove old messages to keep conversation manageable.\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    if len(messages) > 2:\n",
    "        # remove the earliest two messages\n",
    "        return {\"messages\": [RemoveMessage(id=m.id) for m in messages[:2]]}\n",
    "    return None\n",
    "\n",
    "\n",
    "agent = create_agent(\n",
    "    model,\n",
    "    # tools=[],\n",
    "    system_prompt=\"Please be concise and to the point.\",\n",
    "    middleware=[delete_old_messages],\n",
    "    checkpointer=InMemorySaver(),\n",
    ")\n",
    "\n",
    "config: RunnableConfig = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "for event in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"hi! I'm bob\"}]},\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    print([(message.type, message.content) for message in event[\"messages\"]])\n",
    "\n",
    "for event in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"what's my name?\"}]},\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    print([(message.type, message.content) for message in event[\"messages\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba5d3345-d745-48f2-bcf1-08ec97569c40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T12:10:57.249251Z",
     "iopub.status.busy": "2025-10-28T12:10:57.249000Z",
     "iopub.status.idle": "2025-10-28T12:11:15.568425Z",
     "shell.execute_reply": "2025-10-28T12:11:15.567996Z",
     "shell.execute_reply.started": "2025-10-28T12:10:57.249230Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Your name is **Bob**! It's a pleasure to be chatting with you.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n================================== Ai Message ==================================\\n\\nYour name is Bob!\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import SummarizationMiddleware\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "\n",
    "checkpointer = InMemorySaver()\n",
    "\n",
    "agent = create_agent(\n",
    "    model,\n",
    "    tools=[],\n",
    "    middleware=[\n",
    "        SummarizationMiddleware(\n",
    "            model,\n",
    "            max_tokens_before_summary=4000,  # Trigger summarization at 4000 tokens\n",
    "            messages_to_keep=20,  # Keep last 20 messages after summary\n",
    "        )\n",
    "    ],\n",
    "    checkpointer=checkpointer,\n",
    ")\n",
    "\n",
    "config: RunnableConfig = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "agent.invoke({\"messages\": \"hi, my name is bob\"}, config)\n",
    "agent.invoke({\"messages\": \"write a short poem about cats\"}, config)\n",
    "agent.invoke({\"messages\": \"now do the same but for dogs\"}, config)\n",
    "final_response = agent.invoke({\"messages\": \"what's my name?\"}, config)\n",
    "\n",
    "final_response[\"messages\"][-1].pretty_print()\n",
    "\"\"\"\n",
    "================================== Ai Message ==================================\n",
    "\n",
    "Your name is Bob!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a68b5bf-4aba-4d58-938f-dcb90edda302",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T12:11:36.596205Z",
     "iopub.status.busy": "2025-10-28T12:11:36.595983Z",
     "iopub.status.idle": "2025-10-28T12:11:39.783453Z",
     "shell.execute_reply": "2025-10-28T12:11:39.783009Z",
     "shell.execute_reply.started": "2025-10-28T12:11:36.596189Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The user information shows that the current user is John Smith.\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import create_agent, AgentState\n",
    "from langchain.tools import tool, ToolRuntime\n",
    "\n",
    "\n",
    "class CustomState(AgentState):\n",
    "    user_id: str\n",
    "\n",
    "@tool\n",
    "def get_user_info(\n",
    "    runtime: ToolRuntime\n",
    ") -> str:\n",
    "    \"\"\"Look up user info.\"\"\"\n",
    "    user_id = runtime.state[\"user_id\"]\n",
    "    return \"User is John Smith\" if user_id == \"user_123\" else \"Unknown user\"\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[get_user_info],\n",
    "    state_schema=CustomState,\n",
    ")\n",
    "\n",
    "result = agent.invoke({\n",
    "    \"messages\": \"look up user information\",\n",
    "    \"user_id\": \"user_123\"\n",
    "})\n",
    "print(result[\"messages\"][-1].content)\n",
    "# > User is John Smith."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6088f9ce-5b40-4e02-992b-cff9f16af876",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T12:11:43.864083Z",
     "iopub.status.busy": "2025-10-28T12:11:43.863837Z",
     "iopub.status.idle": "2025-10-28T12:11:48.791644Z",
     "shell.execute_reply": "2025-10-28T12:11:48.791207Z",
     "shell.execute_reply.started": "2025-10-28T12:11:43.864066Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='greet the user', additional_kwargs={}, response_metadata={}, id='839dddb0-6318-4977-adb0-53bf6563930d'),\n",
       "  AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 165, 'total_tokens': 174, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 128}, 'prompt_cache_hit_tokens': 128, 'prompt_cache_miss_tokens': 37}, 'model_provider': 'openai', 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_ffc7281d48_prod0820_fp8_kvcache', 'id': '1489e794-119f-48c2-b67c-ad3529ac267c', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--6ef7005f-b992-4111-9884-8d25daf3f1af-0', tool_calls=[{'name': 'update_user_info', 'args': {}, 'id': 'call_00_dzaIjAMxWqxYDt6yanjTZomg', 'type': 'tool_call'}], usage_metadata={'input_tokens': 165, 'output_tokens': 9, 'total_tokens': 174, 'input_token_details': {'cache_read': 128}, 'output_token_details': {}}),\n",
       "  ToolMessage(content='Successfully looked up user information', name='update_user_info', id='d30c0102-5280-4616-a917-68dd34bf0872', tool_call_id='call_00_dzaIjAMxWqxYDt6yanjTZomg'),\n",
       "  AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 183, 'total_tokens': 191, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 128}, 'prompt_cache_hit_tokens': 128, 'prompt_cache_miss_tokens': 55}, 'model_provider': 'openai', 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_ffc7281d48_prod0820_fp8_kvcache', 'id': '7b0a7575-c12c-48c5-b5fe-640211da99ec', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--7c96b367-a943-49a3-8b86-fd4bece95c3f-0', tool_calls=[{'name': 'greet', 'args': {}, 'id': 'call_00_ubEoqioPA7RYg2AJJzV4jUte', 'type': 'tool_call'}], usage_metadata={'input_tokens': 183, 'output_tokens': 8, 'total_tokens': 191, 'input_token_details': {'cache_read': 128}, 'output_token_details': {}}),\n",
       "  ToolMessage(content='Hello John Smith!', name='greet', id='f4be40df-a616-48ae-a26e-d01aa972153b', tool_call_id='call_00_ubEoqioPA7RYg2AJJzV4jUte'),\n",
       "  AIMessage(content=\"Hello John Smith! It's great to see you today! How can I help you?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 198, 'total_tokens': 216, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 192}, 'prompt_cache_hit_tokens': 192, 'prompt_cache_miss_tokens': 6}, 'model_provider': 'openai', 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_ffc7281d48_prod0820_fp8_kvcache', 'id': '426d41c0-b975-41cf-8250-18b6a4d12e7a', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--b748988d-a429-443b-a556-1a57e9d15600-0', usage_metadata={'input_tokens': 198, 'output_tokens': 18, 'total_tokens': 216, 'input_token_details': {'cache_read': 192}, 'output_token_details': {}})],\n",
       " 'user_name': 'John Smith'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.tools import tool, ToolRuntime\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain.messages import ToolMessage\n",
    "from langchain.agents import create_agent, AgentState\n",
    "from langgraph.types import Command\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "class CustomState(AgentState):  \n",
    "    user_name: str\n",
    "\n",
    "class CustomContext(BaseModel):\n",
    "    user_id: str\n",
    "\n",
    "@tool\n",
    "def update_user_info(\n",
    "    runtime: ToolRuntime[CustomContext, CustomState],\n",
    ") -> Command:\n",
    "    \"\"\"Look up and update user info.\"\"\"\n",
    "    user_id = runtime.context.user_id  \n",
    "    name = \"John Smith\" if user_id == \"user_123\" else \"Unknown user\"\n",
    "    return Command(update={\n",
    "        \"user_name\": name,\n",
    "        # update the message history\n",
    "        \"messages\": [\n",
    "            ToolMessage(\n",
    "                \"Successfully looked up user information\",\n",
    "                tool_call_id=runtime.tool_call_id\n",
    "            )\n",
    "        ]\n",
    "    })\n",
    "\n",
    "@tool\n",
    "def greet(\n",
    "    runtime: ToolRuntime[CustomContext, CustomState]\n",
    ") -> str:\n",
    "    \"\"\"Use this to greet the user once you found their info.\"\"\"\n",
    "    user_name = runtime.state[\"user_name\"]\n",
    "    return f\"Hello {user_name}!\"\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[update_user_info, greet],\n",
    "    state_schema=CustomState,\n",
    "    context_schema=CustomContext,  \n",
    ")\n",
    "\n",
    "agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"greet the user\"}]},\n",
    "    context=CustomContext(user_id=\"user_123\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ffd14985-820d-41f7-9045-beb760b41036",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2025-10-28T12:11:53.973906Z",
     "iopub.status.busy": "2025-10-28T12:11:53.973680Z",
     "iopub.status.idle": "2025-10-28T12:11:58.119218Z",
     "shell.execute_reply": "2025-10-28T12:11:58.118763Z",
     "shell.execute_reply.started": "2025-10-28T12:11:53.973891Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is the weather in SF?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I'd be happy to help you check the weather in San Francisco, John Smith. Let me get that information for you.\n",
      "Tool Calls:\n",
      "  get_weather (call_00_bO1PGu1NOnKWZrdj8DYhMnCv)\n",
      " Call ID: call_00_bO1PGu1NOnKWZrdj8DYhMnCv\n",
      "  Args:\n",
      "    city: San Francisco\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: get_weather\n",
      "\n",
      "The weather in San Francisco is always sunny!\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "John Smith, according to the weather information, San Francisco is currently sunny! It looks like a beautiful day there.\n"
     ]
    }
   ],
   "source": [
    "from langchain.messages import AnyMessage\n",
    "from langchain.agents import create_agent, AgentState\n",
    "from typing import TypedDict\n",
    "\n",
    "\n",
    "class CustomContext(TypedDict):\n",
    "    user_name: str\n",
    "\n",
    "\n",
    "from langchain.agents.middleware import dynamic_prompt, ModelRequest\n",
    "\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Get the weather in a city.\"\"\"\n",
    "    return f\"The weather in {city} is always sunny!\"\n",
    "\n",
    "\n",
    "@dynamic_prompt\n",
    "def dynamic_system_prompt(request: ModelRequest) -> str:\n",
    "    user_name = request.runtime.context[\"user_name\"]\n",
    "    system_prompt = f\"You are a helpful assistant. Address the user as {user_name}.\"\n",
    "    return system_prompt\n",
    "\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[get_weather],\n",
    "    middleware=[dynamic_system_prompt],\n",
    "    context_schema=CustomContext,\n",
    ")\n",
    "\n",
    "result = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What is the weather in SF?\"}]},\n",
    "    context=CustomContext(user_name=\"John Smith\"),\n",
    ")\n",
    "for msg in result[\"messages\"]:\n",
    "    msg.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e334f407-973c-42bf-847d-dd9fb1d62c8b",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2025-10-28T12:12:02.228501Z",
     "iopub.status.busy": "2025-10-28T12:12:02.228282Z",
     "iopub.status.idle": "2025-10-28T12:13:18.371589Z",
     "shell.execute_reply": "2025-10-28T12:13:18.371105Z",
     "shell.execute_reply.started": "2025-10-28T12:12:02.228486Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I donâ€™t have access to your name unless you tell me. In this chat, youâ€™re â€œthe user,â€ but if youâ€™d like me to call you by a specific name, just let me know! ðŸ˜Š\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n================================== Ai Message ==================================\\n\\nYour name is Bob. You told me that earlier.\\nIf you'd like me to call you a nickname or use a different name, just say the word.\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.messages import RemoveMessage\n",
    "from langgraph.graph.message import REMOVE_ALL_MESSAGES\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain.agents import create_agent, AgentState\n",
    "from langchain.agents.middleware import before_model\n",
    "from langgraph.runtime import Runtime\n",
    "from typing import Any\n",
    "\n",
    "\n",
    "@before_model\n",
    "def trim_messages(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
    "    \"\"\"Keep only the last few messages to fit context window.\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "    if len(messages) <= 3:\n",
    "        return None  # No changes needed\n",
    "\n",
    "    first_msg = messages[0]\n",
    "    recent_messages = messages[-3:] if len(messages) % 2 == 0 else messages[-4:]\n",
    "    new_messages = [first_msg] + recent_messages\n",
    "\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            RemoveMessage(id=REMOVE_ALL_MESSAGES),\n",
    "            *new_messages\n",
    "        ]\n",
    "    }\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    # tools=tools,\n",
    "    middleware=[trim_messages]\n",
    ")\n",
    "\n",
    "config: RunnableConfig = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "agent.invoke({\"messages\": \"hi, my name is bob\"}, config)\n",
    "agent.invoke({\"messages\": \"write a short poem about cats\"}, config)\n",
    "agent.invoke({\"messages\": \"now do the same but for dogs\"}, config)\n",
    "final_response = agent.invoke({\"messages\": \"what's my name?\"}, config)\n",
    "\n",
    "final_response[\"messages\"][-1].pretty_print()\n",
    "\"\"\"\n",
    "================================== Ai Message ==================================\n",
    "\n",
    "Your name is Bob. You told me that earlier.\n",
    "If you'd like me to call you a nickname or use a different name, just say the word.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1248273c-c921-4136-bf3f-744b882bc9be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T12:16:25.260052Z",
     "iopub.status.busy": "2025-10-28T12:16:25.259791Z",
     "iopub.status.idle": "2025-10-28T12:16:25.267784Z",
     "shell.execute_reply": "2025-10-28T12:16:25.267348Z",
     "shell.execute_reply.started": "2025-10-28T12:16:25.260033Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.messages import RemoveMessage\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain.agents import create_agent, AgentState\n",
    "from langchain.agents.middleware import after_model\n",
    "from langgraph.runtime import Runtime\n",
    "\n",
    "\n",
    "@after_model\n",
    "def validate_response(state: AgentState, runtime: Runtime) -> dict | None:\n",
    "    \"\"\"Remove messages containing sensitive words.\"\"\"\n",
    "    STOP_WORDS = [\"password\", \"secret\"]\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    if any(word in last_message.content for word in STOP_WORDS):\n",
    "        return {\"messages\": [RemoveMessage(id=last_message.id)]}\n",
    "    return None\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[],\n",
    "    middleware=[validate_response],\n",
    "    checkpointer=InMemorySaver(),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
