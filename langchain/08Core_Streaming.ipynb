{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20299de2-ec98-4767-a92e-fe93f93b86dc",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install -U langchain\n",
    "!pip install langchain langchain-community langchain-core\n",
    "!pip install langchain-openai openai\n",
    "!pip install langchain-deepseek\n",
    "!pip install deepseek-api python-dotenv\n",
    "\n",
    "# Installing the OpenAI integration\n",
    "#!pip install -U langchain-openai\n",
    "# Installing the Anthropic integration\n",
    "# !pip install -U langchain-anthropic\n",
    "\n",
    "!pip show langchain-core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f76dc057-7bf5-4c26-941c-d05a9f334cc3",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.execute_input": "2025-10-28T12:39:52.038688Z",
     "iopub.status.busy": "2025-10-28T12:39:52.038393Z",
     "iopub.status.idle": "2025-10-28T12:39:52.043139Z",
     "shell.execute_reply": "2025-10-28T12:39:52.042414Z",
     "shell.execute_reply.started": "2025-10-28T12:39:52.038666Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.tools import tool, ToolRuntime\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "# 设置 DeepSeek 的 API 密钥（LangChain-OpenAI 仍然会查找 OPENAI_API_KEY）\n",
    "# 您可以尝试将 DEEPSEEK_API_KEY 的值赋给 OPENAI_API_KEY 环境变量\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.environ.get(\"DEEPSEEK_API_KEY\", \"sk-943df854319e423ca178e68e4668ca5a\") # 确保这个值是 DeepSeek 的 key\n",
    "\n",
    "# 关键：指定 DeepSeek 的 API 基础 URL\n",
    "DEEPSEEK_BASE_URL = \"https://api.deepseek.com/v1\"\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    model=\"deepseek-chat\", # 使用 DeepSeek 的模型名称\n",
    "    openai_api_base=DEEPSEEK_BASE_URL, # 指定 DeepSeek 的 URL\n",
    "    temperature=0.7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d46c5464-6476-4fc1-b8e5-f5a8d04484f3",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.execute_input": "2025-10-28T12:44:38.004099Z",
     "iopub.status.busy": "2025-10-28T12:44:38.003877Z",
     "iopub.status.idle": "2025-10-28T12:44:41.624122Z",
     "shell.execute_reply": "2025-10-28T12:44:41.623695Z",
     "shell.execute_reply.started": "2025-10-28T12:44:38.004084Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: model\n",
      "content: [{'type': 'text', 'text': \"I'll get the current weather for San Francisco for you.\"}, {'type': 'tool_call', 'name': 'get_weather', 'args': {'city': 'San Francisco'}, 'id': 'call_00_qtncGd1CizOohizAf1Uilez4'}]\n",
      "\n",
      "\n",
      "step: tools\n",
      "content: [{'type': 'text', 'text': \"It's always sunny in San Francisco!\"}]\n",
      "\n",
      "\n",
      "step: model\n",
      "content: [{'type': 'text', 'text': \"According to the weather information, it's always sunny in San Francisco!\"}]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Get weather for a given city.\"\"\"\n",
    "\n",
    "    return f\"It's always sunny in {city}!\"\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[get_weather],\n",
    ")\n",
    "for chunk in agent.stream(  \n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What is the weather in SF?\"}]},\n",
    "    stream_mode=\"updates\",\n",
    "):\n",
    "    for step, data in chunk.items():\n",
    "        print(f\"step: {step}\")\n",
    "        print(f\"content: {data['messages'][-1].content_blocks}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05fadbc-d8fa-453c-9e51-d43739fead53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Get weather for a given city.\"\"\"\n",
    "\n",
    "    return f\"It's always sunny in {city}!\"\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[get_weather],\n",
    ")\n",
    "for token, metadata in agent.stream(  \n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What is the weather in SF?\"}]},\n",
    "    stream_mode=\"messages\",\n",
    "):\n",
    "    print(f\"node: {metadata['langgraph_node']}\")\n",
    "    print(f\"content: {token.content_blocks}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "72c5755e-b80a-40d5-b9b2-cece04f29cfa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T12:46:14.144472Z",
     "iopub.status.busy": "2025-10-28T12:46:14.144244Z",
     "iopub.status.idle": "2025-10-28T12:46:18.640728Z",
     "shell.execute_reply": "2025-10-28T12:46:18.640243Z",
     "shell.execute_reply.started": "2025-10-28T12:46:14.144456Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking up data for city: San Francisco\n",
      "Acquired data for city: San Francisco\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langgraph.config import get_stream_writer  \n",
    "\n",
    "\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Get weather for a given city.\"\"\"\n",
    "    writer = get_stream_writer()  \n",
    "    # stream any arbitrary data\n",
    "    writer(f\"Looking up data for city: {city}\")\n",
    "    writer(f\"Acquired data for city: {city}\")\n",
    "    return f\"It's always sunny in {city}!\"\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[get_weather],\n",
    ")\n",
    "\n",
    "for chunk in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What is the weather in SF?\"}]},\n",
    "    stream_mode=\"custom\"\n",
    "):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b7887e28-e6e2-4d64-874e-7dcf49ded505",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2025-10-28T12:48:01.829715Z",
     "iopub.status.busy": "2025-10-28T12:48:01.829482Z",
     "iopub.status.idle": "2025-10-28T12:48:06.485635Z",
     "shell.execute_reply": "2025-10-28T12:48:06.485189Z",
     "shell.execute_reply.started": "2025-10-28T12:48:01.829701Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content: {'model': {'messages': [AIMessage(content=\"I'll get the current weather for San Francisco for you.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 153, 'total_tokens': 180, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 128}, 'prompt_cache_hit_tokens': 128, 'prompt_cache_miss_tokens': 25}, 'model_provider': 'openai', 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_ffc7281d48_prod0820_fp8_kvcache', 'id': '501431bf-8241-4cb7-a807-fac600cb0c23', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--aabcc28c-7637-4f65-a15b-434dc384e5d0-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'San Francisco'}, 'id': 'call_00_SNfiCSVaFwYBAyYhzGLUf4CV', 'type': 'tool_call'}], usage_metadata={'input_tokens': 153, 'output_tokens': 27, 'total_tokens': 180, 'input_token_details': {'cache_read': 128}, 'output_token_details': {}})]}}\n",
      "\n",
      "\n",
      "content: Looking up data for city: San Francisco\n",
      "\n",
      "\n",
      "content: Acquired data for city: San Francisco\n",
      "\n",
      "\n",
      "content: {'tools': {'messages': [ToolMessage(content=\"It's always sunny in San Francisco!\", name='get_weather', id='f000b013-8aab-45b7-ac88-f9619168f137', tool_call_id='call_00_SNfiCSVaFwYBAyYhzGLUf4CV')]}}\n",
      "\n",
      "\n",
      "content: {'model': {'messages': [AIMessage(content=\"According to the weather information, it's always sunny in San Francisco!\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 191, 'total_tokens': 205, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 128}, 'prompt_cache_hit_tokens': 128, 'prompt_cache_miss_tokens': 63}, 'model_provider': 'openai', 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_ffc7281d48_prod0820_fp8_kvcache', 'id': '29a97d4c-098f-4339-88c4-d5760d8ef4aa', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--922722f0-e4a4-461a-91d2-09b6486f0450-0', usage_metadata={'input_tokens': 191, 'output_tokens': 14, 'total_tokens': 205, 'input_token_details': {'cache_read': 128}, 'output_token_details': {}})]}}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langgraph.config import get_stream_writer\n",
    "\n",
    "\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Get weather for a given city.\"\"\"\n",
    "    writer = get_stream_writer()\n",
    "    writer(f\"Looking up data for city: {city}\")\n",
    "    writer(f\"Acquired data for city: {city}\")\n",
    "    return f\"It's always sunny in {city}!\"\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[get_weather],\n",
    ")\n",
    "\n",
    "for stream_mode, chunk in agent.stream(  \n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What is the weather in SF?\"}]},\n",
    "    stream_mode=[\"updates\", \"custom\"]\n",
    "):\n",
    "    # print(f\"stream_mode: {stream_mode}\")\n",
    "    print(f\"content: {chunk}\")\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
