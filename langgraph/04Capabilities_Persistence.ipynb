{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20299de2-ec98-4767-a92e-fe93f93b86dc",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2025-11-03T12:02:45.579890Z",
     "iopub.status.busy": "2025-11-03T12:02:45.579748Z",
     "iopub.status.idle": "2025-11-03T12:03:05.487663Z",
     "shell.execute_reply": "2025-11-03T12:03:05.487148Z",
     "shell.execute_reply.started": "2025-11-03T12:02:45.579874Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.cloud.aliyuncs.com/pypi/simple\n",
      "Collecting langgraph\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/d7/b1/9f4912e13d4ed691f2685c8a4b764b5a9237a30cca0c5782bc213d9f0a9a/langgraph-1.0.2-py3-none-any.whl (156 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 kB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting langchain-core>=0.1 (from langgraph)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/52/54/3aed89938a42cf7115575c333647551e35adc380feed651105d2d86c22f5/langchain_core-1.0.2-py3-none-any.whl (469 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.3/469.3 kB\u001b[0m \u001b[31m65.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting langgraph-checkpoint<4.0.0,>=2.1.0 (from langgraph)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/85/2a/2efe0b5a72c41e3a936c81c5f5d8693987a1b260287ff1bbebaae1b7b888/langgraph_checkpoint-3.0.0-py3-none-any.whl (46 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.1/46.1 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting langgraph-prebuilt<1.1.0,>=1.0.2 (from langgraph)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/27/2f/9a7d00d4afa036e65294059c7c912002fb72ba5dbbd5c2a871ca06360278/langgraph_prebuilt-1.0.2-py3-none-any.whl (34 kB)\n",
      "Collecting langgraph-sdk<0.3.0,>=0.2.2 (from langgraph)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/66/05/b2d34e16638241e6f27a6946d28160d4b8b641383787646d41a3727e0896/langgraph_sdk-0.2.9-py3-none-any.whl (56 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.11/site-packages (from langgraph) (2.11.10)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.11/site-packages (from langgraph) (3.6.0)\n",
      "Collecting jsonpatch<2.0.0,>=1.33.0 (from langchain-core>=0.1->langgraph)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/73/07/02e16ed01e04a374e644b575638ec7987ae846d25ad97bcc9945a3ee4b0e/jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Collecting langsmith<1.0.0,>=0.3.45 (from langchain-core>=0.1->langgraph)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/1f/38/9a97f650b8cdb2ba0356d65aef9239f4a30db69ae44c30daa2cf8dd3f350/langsmith-0.4.39-py3-none-any.whl (397 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m397.8/397.8 kB\u001b[0m \u001b[31m85.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.11/site-packages (from langchain-core>=0.1->langgraph) (24.2)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.11/site-packages (from langchain-core>=0.1->langgraph) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/site-packages (from langchain-core>=0.1->langgraph) (9.1.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.11/site-packages (from langchain-core>=0.1->langgraph) (4.15.0)\n",
      "Collecting ormsgpack>=1.10.0 (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/1c/fa/e7e06835bfea9adeef43915143ce818098aecab0cbd3df584815adf3e399/ormsgpack-1.11.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (207 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.4/207.4 kB\u001b[0m \u001b[31m57.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.11/site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/site-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/site-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/site-packages (from pydantic>=2.7.4->langgraph) (0.4.2)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.11/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (4.11.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.0.9)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.11/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core>=0.1->langgraph) (3.0.0)\n",
      "Collecting requests-toolbelt>=1.0.0 (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/3f/51/d4db610ef29373b879047326cbf6fa98b6c1969d6f6dc423279de2b1be2c/requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.11/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (2.32.3)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.11/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (0.25.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (2.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.3.1)\n",
      "\u001b[33mDEPRECATION: pytorch-lightning 1.7.7 has a non-standard dependency specifier torch>=1.9.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: ormsgpack, jsonpatch, requests-toolbelt, langsmith, langgraph-sdk, langchain-core, langgraph-checkpoint, langgraph-prebuilt, langgraph\n",
      "Successfully installed jsonpatch-1.33 langchain-core-1.0.2 langgraph-1.0.2 langgraph-checkpoint-3.0.0 langgraph-prebuilt-1.0.2 langgraph-sdk-0.2.9 langsmith-0.4.39 ormsgpack-1.11.0 requests-toolbelt-1.0.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Looking in indexes: https://mirrors.cloud.aliyuncs.com/pypi/simple\n",
      "Collecting langchain\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/68/c8/b5dcfdde8b96369e5445f0fbac52fe8495bbd11b23ca83691d90d464eb15/langchain-1.0.3-py3-none-any.whl (91 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: langchain-core<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/site-packages (from langchain) (1.0.2)\n",
      "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in /usr/local/lib/python3.11/site-packages (from langchain) (1.0.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/site-packages (from langchain) (2.11.10)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.11/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.11/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (0.4.39)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.11/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (24.2)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.11/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (9.1.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.11/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (4.15.0)\n",
      "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /usr/local/lib/python3.11/site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.0.0)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /usr/local/lib/python3.11/site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (1.0.2)\n",
      "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /usr/local/lib/python3.11/site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (0.2.9)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.11/site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.6.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain) (3.0.0)\n",
      "Requirement already satisfied: ormsgpack>=1.10.0 in /usr/local/lib/python3.11/site-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain) (1.11.0)\n",
      "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.11/site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.11/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.11/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain) (2.32.3)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.11/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain) (0.25.0)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.11/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (4.11.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (1.0.9)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.11/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (0.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain) (2.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (1.3.1)\n",
      "\u001b[33mDEPRECATION: pytorch-lightning 1.7.7 has a non-standard dependency specifier torch>=1.9.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: langchain\n",
      "Successfully installed langchain-1.0.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Looking in indexes: https://mirrors.cloud.aliyuncs.com/pypi/simple\n",
      "Collecting langchain-openai\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/62/c0/06d74093e3e798eb464ef76f53d031235b87feccdadbbf6f7b8409043e4d/langchain_openai-1.0.1-py3-none-any.whl (81 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.9/81.9 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: openai in /usr/local/lib/python3.11/site-packages (2.3.0)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/site-packages (from langchain-openai) (1.0.2)\n",
      "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/site-packages (from langchain-openai) (0.12.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/site-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.11/site-packages (from openai) (0.11.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/site-packages (from openai) (2.11.10)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/site-packages (from openai) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.11/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-openai) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.11/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-openai) (0.4.39)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.11/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-openai) (24.2)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.11/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-openai) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-openai) (9.1.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2.32.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain-openai) (3.0.0)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.11/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-openai) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.11/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-openai) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.11/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-openai) (0.25.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain-openai) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain-openai) (2.3.0)\n",
      "\u001b[33mDEPRECATION: pytorch-lightning 1.7.7 has a non-standard dependency specifier torch>=1.9.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: langchain-openai\n",
      "Successfully installed langchain-openai-1.0.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Looking in indexes: https://mirrors.cloud.aliyuncs.com/pypi/simple\n",
      "Collecting langchain-deepseek\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/4f/35/c84672001fd9899f8e40f99f81c81235d2093386ce3d159111002edd8365/langchain_deepseek-1.0.0-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/site-packages (from langchain-deepseek) (1.0.2)\n",
      "Requirement already satisfied: langchain-openai<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/site-packages (from langchain-deepseek) (1.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.11/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-deepseek) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.11/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-deepseek) (0.4.39)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.11/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-deepseek) (24.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-deepseek) (2.11.10)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.11/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-deepseek) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-deepseek) (9.1.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.11/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-deepseek) (4.15.0)\n",
      "Requirement already satisfied: openai<3.0.0,>=1.109.1 in /usr/local/lib/python3.11/site-packages (from langchain-openai<2.0.0,>=1.0.0->langchain-deepseek) (2.3.0)\n",
      "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/site-packages (from langchain-openai<2.0.0,>=1.0.0->langchain-deepseek) (0.12.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain-deepseek) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-deepseek) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.11/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-deepseek) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.11/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-deepseek) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.11/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-deepseek) (2.32.3)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.11/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-deepseek) (0.25.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai<2.0.0,>=1.0.0->langchain-deepseek) (4.11.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai<2.0.0,>=1.0.0->langchain-deepseek) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.11/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai<2.0.0,>=1.0.0->langchain-deepseek) (0.11.0)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai<2.0.0,>=1.0.0->langchain-deepseek) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai<2.0.0,>=1.0.0->langchain-deepseek) (4.67.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.0->langchain-deepseek) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.0->langchain-deepseek) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.0->langchain-deepseek) (0.4.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai<2.0.0,>=1.0.0->langchain-deepseek) (2024.11.6)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai<3.0.0,>=1.109.1->langchain-openai<2.0.0,>=1.0.0->langchain-deepseek) (3.10)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-deepseek) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-deepseek) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-deepseek) (0.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-deepseek) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-deepseek) (2.3.0)\n",
      "\u001b[33mDEPRECATION: pytorch-lightning 1.7.7 has a non-standard dependency specifier torch>=1.9.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: langchain-deepseek\n",
      "Successfully installed langchain-deepseek-1.0.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# !uv add langgraph\n",
    "\n",
    "!pip install -U langgraph\n",
    "!pip install -U langchain\n",
    "!pip install langchain-openai openai\n",
    "!pip install langchain-deepseek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f76dc057-7bf5-4c26-941c-d05a9f334cc3",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2025-11-03T12:04:05.365399Z",
     "iopub.status.busy": "2025-11-03T12:04:05.365198Z",
     "iopub.status.idle": "2025-11-03T12:04:10.093753Z",
     "shell.execute_reply": "2025-11-03T12:04:10.093311Z",
     "shell.execute_reply.started": "2025-11-03T12:04:05.365382Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.tools import tool, ToolRuntime\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "# 设置 DeepSeek 的 API 密钥（LangChain-OpenAI 仍然会查找 OPENAI_API_KEY）\n",
    "os.environ['DEEPSEEK_API_KEY'] = 'your_deepseek_api_key_here'\n",
    "\n",
    "# 您可以尝试将 DEEPSEEK_API_KEY 的值赋给 OPENAI_API_KEY 环境变量\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv('DEEPSEEK_API_KEY') # 确保这个值是 DeepSeek 的 key\n",
    "\n",
    "# 关键：指定 DeepSeek 的 API 基础 URL\n",
    "DEEPSEEK_BASE_URL = \"https://api.deepseek.com/v1\"\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    model=\"deepseek-chat\", # 使用 DeepSeek 的模型名称\n",
    "    openai_api_base=DEEPSEEK_BASE_URL, # 指定 DeepSeek 的 URL\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1889bd30-0123-4996-ae25-62af33ff84dd",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2025-11-03T12:21:23.878691Z",
     "iopub.status.busy": "2025-11-03T12:21:23.878476Z",
     "iopub.status.idle": "2025-11-03T12:21:23.887606Z",
     "shell.execute_reply": "2025-11-03T12:21:23.887240Z",
     "shell.execute_reply.started": "2025-11-03T12:21:23.878676Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'foo': 'b', 'bar': ['a', 'b']}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from operator import add\n",
    "\n",
    "class State(TypedDict):\n",
    "    foo: str\n",
    "    bar: Annotated[list[str], add]\n",
    "\n",
    "def node_a(state: State):\n",
    "    return {\"foo\": \"a\", \"bar\": [\"a\"]}\n",
    "\n",
    "def node_b(state: State):\n",
    "    return {\"foo\": \"b\", \"bar\": [\"b\"]}\n",
    "\n",
    "\n",
    "workflow = StateGraph(State)\n",
    "workflow.add_node(node_a)\n",
    "workflow.add_node(node_b)\n",
    "workflow.add_edge(START, \"node_a\")\n",
    "workflow.add_edge(\"node_a\", \"node_b\")\n",
    "workflow.add_edge(\"node_b\", END)\n",
    "\n",
    "checkpointer = InMemorySaver()\n",
    "graph = workflow.compile(checkpointer=checkpointer)\n",
    "\n",
    "config: RunnableConfig = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "graph.invoke({\"foo\": \"\"}, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "950f8ac9-e937-4a48-a739-b50b8b512612",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2025-11-03T12:21:55.059753Z",
     "iopub.status.busy": "2025-11-03T12:21:55.059552Z",
     "iopub.status.idle": "2025-11-03T12:21:55.062974Z",
     "shell.execute_reply": "2025-11-03T12:21:55.062500Z",
     "shell.execute_reply.started": "2025-11-03T12:21:55.059738Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'foo': 'b', 'bar': ['a', 'b']}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0b8af9-cdaa-6a69-8002-3a6edb9ab7d3'}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, created_at='2025-11-03T12:21:23.884899+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0b8af9-cda9-6911-8001-94cdfe089f89'}}, tasks=(), interrupts=())"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the latest state snapshot\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "graph.get_state(config)\n",
    "\n",
    "# # get a state snapshot for a specific checkpoint_id\n",
    "# config = {\"configurable\": {\"thread_id\": \"1\" }}\n",
    "# graph.get_state(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ee1764-90fb-4915-a4f6-b848a611a95b",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "list(graph.get_state_history(config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7965722a-30f1-4443-b882-b99e6f13bff0",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2025-11-03T12:24:16.193637Z",
     "iopub.status.busy": "2025-11-03T12:24:16.193412Z",
     "iopub.status.idle": "2025-11-03T12:24:16.197300Z",
     "shell.execute_reply": "2025-11-03T12:24:16.196763Z",
     "shell.execute_reply.started": "2025-11-03T12:24:16.193614Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'foo': 'b', 'bar': ['a', 'b']}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "graph.invoke(None, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c3f6baa8-577d-4667-97e2-27659e2de429",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2025-11-03T12:28:48.494832Z",
     "iopub.status.busy": "2025-11-03T12:28:48.494640Z",
     "iopub.status.idle": "2025-11-03T12:28:48.499801Z",
     "shell.execute_reply": "2025-11-03T12:28:48.499279Z",
     "shell.execute_reply.started": "2025-11-03T12:28:48.494818Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'foo': 2, 'bar': ['a', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b']}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from operator import add\n",
    "\n",
    "class State(TypedDict):\n",
    "    foo: int\n",
    "    bar: Annotated[list[str], add]\n",
    "\n",
    "graph.update_state(config, {\"foo\": 2, \"bar\": [\"b\"]})\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "graph.invoke(None, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "07fa6a67-ac12-415d-b52f-6eb96f12de5b",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2025-11-03T12:50:42.032868Z",
     "iopub.status.busy": "2025-11-03T12:50:42.032671Z",
     "iopub.status.idle": "2025-11-03T12:50:42.036970Z",
     "shell.execute_reply": "2025-11-03T12:50:42.036608Z",
     "shell.execute_reply.started": "2025-11-03T12:50:42.032854Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'namespace': ['334', 'memories'],\n",
       " 'key': '6a3ccd7f-1de8-4c3f-bf09-1d0abdbafb2a',\n",
       " 'value': {'food_preference': 'I like pizza'},\n",
       " 'created_at': '2025-11-03T12:50:42.034297+00:00',\n",
       " 'updated_at': '2025-11-03T12:50:42.034299+00:00',\n",
       " 'score': None}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import uuid\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "\n",
    "in_memory_store = InMemoryStore()\n",
    "user_id = \"334\"\n",
    "namespace_for_memory = (user_id, \"memories\")\n",
    "\n",
    "memory_id = str(uuid.uuid4())\n",
    "memory = {\"food_preference\" : \"I like pizza\"}\n",
    "in_memory_store.put(namespace_for_memory, memory_id, memory)\n",
    "memories = in_memory_store.search(namespace_for_memory)\n",
    "memories[0].dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9674b3c7-2665-4430-9e16-20e8689fa823",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2025-11-03T12:54:48.725381Z",
     "iopub.status.busy": "2025-11-03T12:54:48.725180Z",
     "iopub.status.idle": "2025-11-03T12:54:48.728956Z",
     "shell.execute_reply": "2025-11-03T12:54:48.728482Z",
     "shell.execute_reply.started": "2025-11-03T12:54:48.725366Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import uuid\n",
    "from langchain.embeddings import init_embeddings\n",
    "\n",
    "\n",
    "store = InMemoryStore(\n",
    "    # index={\n",
    "    #     # \"embed\": init_embeddings(\"openai:langchain-openai\"),  # Embedding provider\n",
    "    #     \"dims\": 1536,                              # Embedding dimensions\n",
    "    #     \"fields\": [\"food_preference\", \"$\"]              # Fields to embed\n",
    "    # }\n",
    ")\n",
    "\n",
    "# Find memories about food preferences\n",
    "# (This can be done after putting memories into the store)\n",
    "memories = store.search(\n",
    "    namespace_for_memory,\n",
    "    query=\"What does the user like to eat?\",\n",
    "    limit=3  # Return top 3 matches\n",
    ")\n",
    "\n",
    "# Store with specific fields to embed\n",
    "store.put(\n",
    "    namespace_for_memory,\n",
    "    str(\"1123\"),\n",
    "    {\n",
    "        \"food_preference\": \"I love Italian cuisine\",\n",
    "        \"context\": \"Discussing dinner plans\"\n",
    "    },\n",
    "    index=[\"food_preference\"]  # Only embed \"food_preferences\" field\n",
    ")\n",
    "\n",
    "# Store without embedding (still retrievable, but not searchable)\n",
    "store.put(\n",
    "    namespace_for_memory,\n",
    "    str(uuid.uuid4()),\n",
    "    {\"system_info\": \"Last updated: 2024-01-01\"},\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52638b04-ee21-4982-8de8-7ee14a942371",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afaa211c-c1c1-47cf-ae31-8a0cff2f3ea6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "# We need this because we want to enable threads (conversations)\n",
    "checkpointer = InMemorySaver()\n",
    "\n",
    "# ... Define the graph ...\n",
    "\n",
    "# Compile the graph with the checkpointer and store\n",
    "graph = graph.compile(checkpointer=checkpointer, store=in_memory_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "14ba2452-8941-4972-89b9-48c4f5c73fd0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T12:57:52.822245Z",
     "iopub.status.busy": "2025-11-03T12:57:52.822039Z",
     "iopub.status.idle": "2025-11-03T12:57:52.827612Z",
     "shell.execute_reply": "2025-11-03T12:57:52.827274Z",
     "shell.execute_reply.started": "2025-11-03T12:57:52.822229Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'node_a': {'foo': 'a', 'bar': ['a']}}\n",
      "{'node_b': {'foo': 'b', 'bar': ['b']}}\n"
     ]
    }
   ],
   "source": [
    "# Invoke the graph\n",
    "user_id = \"1\"\n",
    "config = {\"configurable\": {\"thread_id\": \"1\", \"user_id\": user_id}}\n",
    "\n",
    "# First let's just say hi to the AI\n",
    "for update in graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"hi\"}]}, config, stream_mode=\"updates\"\n",
    "):\n",
    "    print(update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9b7746e3-eda5-4464-acde-f7d4f5e03bf2",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.execute_input": "2025-11-03T12:59:36.601925Z",
     "iopub.status.busy": "2025-11-03T12:59:36.601716Z",
     "iopub.status.idle": "2025-11-03T12:59:36.626235Z",
     "shell.execute_reply": "2025-11-03T12:59:36.625740Z",
     "shell.execute_reply.started": "2025-11-03T12:59:36.601909Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MessagesState' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[102]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mupdate_memory\u001b[39m(state: \u001b[43mMessagesState\u001b[49m, config: RunnableConfig, store: BaseStore):\n\u001b[32m      2\u001b[39m \n\u001b[32m      3\u001b[39m     \u001b[38;5;66;03m# Get the user id from the config\u001b[39;00m\n\u001b[32m      4\u001b[39m     user_id = config[\u001b[33m\"\u001b[39m\u001b[33mconfigurable\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33muser_id\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m      6\u001b[39m     \u001b[38;5;66;03m# Namespace the memory\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'MessagesState' is not defined"
     ]
    }
   ],
   "source": [
    "def update_memory(state: MessagesState, config: RunnableConfig, *, store: BaseStore):\n",
    "\n",
    "    # Get the user id from the config\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "\n",
    "    # Namespace the memory\n",
    "    namespace = (user_id, \"memories\")\n",
    "\n",
    "    # ... Analyze conversation and create a new memory\n",
    "\n",
    "    # Create a new memory ID\n",
    "    memory_id = str(uuid.uuid4())\n",
    "\n",
    "    # We create a new memory\n",
    "    store.put(namespace, memory_id, {\"memory\": memory})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b168f7-d001-476a-b04b-26295acd7f55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "bccc915c-3ab4-4cc1-8fe2-68d9e6a703cd",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2025-11-03T13:20:17.571807Z",
     "iopub.status.busy": "2025-11-03T13:20:17.571611Z",
     "iopub.status.idle": "2025-11-03T13:20:17.597981Z",
     "shell.execute_reply": "2025-11-03T13:20:17.597429Z",
     "shell.execute_reply.started": "2025-11-03T13:20:17.571793Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'BaseStore' from 'langgraph.store' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[118]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmessages\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseMessage  \u001b[38;5;66;03m# ✅ 关键导入！\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlanggraph\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseStore  \u001b[38;5;66;03m# ✅ 关键导入！\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Annotated\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping_extensions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TypedDict\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'BaseStore' from 'langgraph.store' (unknown location)"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import BaseMessage  # ✅ 关键导入！\n",
    "from langgraph.store import BaseStore  # ✅ 关键导入！\n",
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langgraph.store import BaseStore\n",
    "from operator import add\n",
    "\n",
    "# 1. 定义 MessagesState\n",
    "class MessagesState(TypedDict):\n",
    "    messages: Annotated[list[BaseMessage], add]\n",
    "\n",
    "def call_model(state: MessagesState, config: RunnableConfig, *, store: BaseStore):\n",
    "    # Get the user id from the config\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "\n",
    "    # Namespace the memory\n",
    "    namespace = (user_id, \"memories\")\n",
    "\n",
    "    # Search based on the most recent message\n",
    "    memories = store.search(\n",
    "        namespace,\n",
    "        query=state[\"messages\"][-1].content,\n",
    "        limit=3\n",
    "    )\n",
    "    info = \"\\n\".join([d.value[\"memory\"] for d in memories])\n",
    "\n",
    "    # ... Use memories in the model call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "27b1a6b3-1ce9-4ebd-b6bf-5a204955bf49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T13:02:29.310128Z",
     "iopub.status.busy": "2025-11-03T13:02:29.309906Z",
     "iopub.status.idle": "2025-11-03T13:02:29.315723Z",
     "shell.execute_reply": "2025-11-03T13:02:29.315311Z",
     "shell.execute_reply.started": "2025-11-03T13:02:29.310112Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'node_a': {'foo': 'a', 'bar': ['a']}}\n",
      "{'node_b': {'foo': 'b', 'bar': ['b']}}\n"
     ]
    }
   ],
   "source": [
    "# Invoke the graph\n",
    "config = {\"configurable\": {\"thread_id\": \"2\", \"user_id\": \"1\"}}\n",
    "\n",
    "# Let's say hi again\n",
    "for update in graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"hi, tell me about my memories\"}]}, config, stream_mode=\"updates\"\n",
    "):\n",
    "    print(update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "62f4354c-ffdd-4f02-b9e0-2aa5fb1ce178",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.execute_input": "2025-11-03T13:28:59.263235Z",
     "iopub.status.busy": "2025-11-03T13:28:59.263033Z",
     "iopub.status.idle": "2025-11-03T13:28:59.272435Z",
     "shell.execute_reply": "2025-11-03T13:28:59.272031Z",
     "shell.execute_reply.started": "2025-11-03T13:28:59.263220Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'foo': 'b', 'bar': ['a', 'b']}\n"
     ]
    }
   ],
   "source": [
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from operator import add\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langgraph.checkpoint.serde.jsonplus import JsonPlusSerializer\n",
    "\n",
    "class State(TypedDict):\n",
    "    foo: str\n",
    "    bar: Annotated[list[str], add]\n",
    "\n",
    "def node_a(state: State):\n",
    "    return {\"foo\": \"a\", \"bar\": [\"a\"]}\n",
    "\n",
    "def node_b(state: State):\n",
    "    return {\"foo\": \"b\", \"bar\": [\"b\"]}\n",
    "\n",
    "# 1. 定义图\n",
    "workflow = StateGraph(State)\n",
    "workflow.add_node(\"node_a\", node_a)\n",
    "workflow.add_node(\"node_b\", node_b)\n",
    "workflow.add_edge(START, \"node_a\")\n",
    "workflow.add_edge(\"node_a\", \"node_b\")\n",
    "workflow.add_edge(\"node_b\", END)\n",
    "\n",
    "# 2. 编译图（✅ 仅此一次！）\n",
    "checkpointer = InMemorySaver(serde=JsonPlusSerializer(pickle_fallback=True))\n",
    "graph = workflow.compile(checkpointer=checkpointer)\n",
    "\n",
    "# 3. 调用\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "result = graph.invoke({\"foo\": \"\", \"bar\": []}, config)\n",
    "print(result)  # {'foo': 'b', 'bar': ['a', 'b']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "dd5a7a19-24e3-4c6e-aeca-a5fc129e798d",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2025-11-03T13:28:50.106188Z",
     "iopub.status.busy": "2025-11-03T13:28:50.105967Z",
     "iopub.status.idle": "2025-11-03T13:28:50.127428Z",
     "shell.execute_reply": "2025-11-03T13:28:50.126933Z",
     "shell.execute_reply.started": "2025-11-03T13:28:50.106173Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langgraph.checkpoint.sqlite'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[125]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msqlite3\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlanggraph\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcheckpoint\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mserde\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mencrypted\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m EncryptedSerializer\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlanggraph\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcheckpoint\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msqlite\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SqliteSaver\n\u001b[32m      6\u001b[39m serde = EncryptedSerializer.from_pycryptodome_aes()  \u001b[38;5;66;03m# reads LANGGRAPH_AES_KEY\u001b[39;00m\n\u001b[32m      7\u001b[39m checkpointer = SqliteSaver(sqlite3.connect(\u001b[33m\"\u001b[39m\u001b[33mcheckpoint.db\u001b[39m\u001b[33m\"\u001b[39m), serde=serde)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'langgraph.checkpoint.sqlite'"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "from langgraph.checkpoint.serde.encrypted import EncryptedSerializer\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "\n",
    "serde = EncryptedSerializer.from_pycryptodome_aes()  # reads LANGGRAPH_AES_KEY\n",
    "checkpointer = SqliteSaver(sqlite3.connect(\"checkpoint.db\"), serde=serde)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04bcc4a3-8450-403c-83b3-fdc15886478d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "57f8a0b4-cf73-46c1-af42-f3fd5ba98e82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T13:28:54.592290Z",
     "iopub.status.busy": "2025-11-03T13:28:54.592083Z",
     "iopub.status.idle": "2025-11-03T13:28:54.615734Z",
     "shell.execute_reply": "2025-11-03T13:28:54.615211Z",
     "shell.execute_reply.started": "2025-11-03T13:28:54.592274Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langgraph.checkpoint.postgres'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[126]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlanggraph\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcheckpoint\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mserde\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mencrypted\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m EncryptedSerializer\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlanggraph\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcheckpoint\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpostgres\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PostgresSaver\n\u001b[32m      4\u001b[39m serde = EncryptedSerializer.from_pycryptodome_aes()\n\u001b[32m      5\u001b[39m checkpointer = PostgresSaver.from_conn_string(\u001b[33m\"\u001b[39m\u001b[33mpostgresql://...\u001b[39m\u001b[33m\"\u001b[39m, serde=serde)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'langgraph.checkpoint.postgres'"
     ]
    }
   ],
   "source": [
    "from langgraph.checkpoint.serde.encrypted import EncryptedSerializer\n",
    "from langgraph.checkpoint.postgres import PostgresSaver\n",
    "\n",
    "serde = EncryptedSerializer.from_pycryptodome_aes()\n",
    "checkpointer = PostgresSaver.from_conn_string(\"postgresql://...\", serde=serde)\n",
    "checkpointer.setup()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
