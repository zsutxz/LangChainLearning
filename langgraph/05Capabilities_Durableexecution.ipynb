{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20299de2-ec98-4767-a92e-fe93f93b86dc",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2025-11-03T13:41:03.481597Z",
     "iopub.status.busy": "2025-11-03T13:41:03.481382Z",
     "iopub.status.idle": "2025-11-03T13:41:20.891510Z",
     "shell.execute_reply": "2025-11-03T13:41:20.890967Z",
     "shell.execute_reply.started": "2025-11-03T13:41:03.481581Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.cloud.aliyuncs.com/pypi/simple\n",
      "Requirement already satisfied: langgraph in /usr/local/lib/python3.11/site-packages (1.0.2)\n",
      "Requirement already satisfied: langchain-core>=0.1 in /usr/local/lib/python3.11/site-packages (from langgraph) (1.0.2)\n",
      "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /usr/local/lib/python3.11/site-packages (from langgraph) (3.0.0)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /usr/local/lib/python3.11/site-packages (from langgraph) (1.0.2)\n",
      "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /usr/local/lib/python3.11/site-packages (from langgraph) (0.2.9)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.11/site-packages (from langgraph) (2.11.10)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.11/site-packages (from langgraph) (3.6.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.11/site-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.11/site-packages (from langchain-core>=0.1->langgraph) (0.4.39)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.11/site-packages (from langchain-core>=0.1->langgraph) (24.2)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.11/site-packages (from langchain-core>=0.1->langgraph) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/site-packages (from langchain-core>=0.1->langgraph) (9.1.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.11/site-packages (from langchain-core>=0.1->langgraph) (4.15.0)\n",
      "Requirement already satisfied: ormsgpack>=1.10.0 in /usr/local/lib/python3.11/site-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph) (1.11.0)\n",
      "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.11/site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/site-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/site-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/site-packages (from pydantic>=2.7.4->langgraph) (0.4.2)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.11/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (4.11.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.0.9)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.11/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core>=0.1->langgraph) (3.0.0)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.11/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.11/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (2.32.3)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.11/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (0.25.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (2.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.3.1)\n",
      "\u001b[33mDEPRECATION: pytorch-lightning 1.7.7 has a non-standard dependency specifier torch>=1.9.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Looking in indexes: https://mirrors.cloud.aliyuncs.com/pypi/simple\n",
      "Requirement already satisfied: langchain in /usr/local/lib/python3.11/site-packages (1.0.3)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/site-packages (from langchain) (1.0.2)\n",
      "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in /usr/local/lib/python3.11/site-packages (from langchain) (1.0.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/site-packages (from langchain) (2.11.10)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.11/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.11/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (0.4.39)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.11/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (24.2)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.11/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (9.1.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.11/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (4.15.0)\n",
      "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /usr/local/lib/python3.11/site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.0.0)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /usr/local/lib/python3.11/site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (1.0.2)\n",
      "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /usr/local/lib/python3.11/site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (0.2.9)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.11/site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.6.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain) (3.0.0)\n",
      "Requirement already satisfied: ormsgpack>=1.10.0 in /usr/local/lib/python3.11/site-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain) (1.11.0)\n",
      "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.11/site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.11/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.11/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain) (2.32.3)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.11/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain) (0.25.0)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.11/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (4.11.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (1.0.9)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.11/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (0.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain) (2.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (1.3.1)\n",
      "\u001b[33mDEPRECATION: pytorch-lightning 1.7.7 has a non-standard dependency specifier torch>=1.9.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Looking in indexes: https://mirrors.cloud.aliyuncs.com/pypi/simple\n",
      "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.11/site-packages (1.0.1)\n",
      "Requirement already satisfied: openai in /usr/local/lib/python3.11/site-packages (2.3.0)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/site-packages (from langchain-openai) (1.0.2)\n",
      "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/site-packages (from langchain-openai) (0.12.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/site-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.11/site-packages (from openai) (0.11.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/site-packages (from openai) (2.11.10)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/site-packages (from openai) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.11/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-openai) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.11/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-openai) (0.4.39)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.11/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-openai) (24.2)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.11/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-openai) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-openai) (9.1.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2.32.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain-openai) (3.0.0)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.11/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-openai) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.11/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-openai) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.11/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-openai) (0.25.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain-openai) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain-openai) (2.3.0)\n",
      "\u001b[33mDEPRECATION: pytorch-lightning 1.7.7 has a non-standard dependency specifier torch>=1.9.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Looking in indexes: https://mirrors.cloud.aliyuncs.com/pypi/simple\n",
      "Requirement already satisfied: langchain-deepseek in /usr/local/lib/python3.11/site-packages (1.0.0)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/site-packages (from langchain-deepseek) (1.0.2)\n",
      "Requirement already satisfied: langchain-openai<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/site-packages (from langchain-deepseek) (1.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.11/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-deepseek) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.11/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-deepseek) (0.4.39)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.11/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-deepseek) (24.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-deepseek) (2.11.10)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.11/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-deepseek) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-deepseek) (9.1.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.11/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-deepseek) (4.15.0)\n",
      "Requirement already satisfied: openai<3.0.0,>=1.109.1 in /usr/local/lib/python3.11/site-packages (from langchain-openai<2.0.0,>=1.0.0->langchain-deepseek) (2.3.0)\n",
      "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/site-packages (from langchain-openai<2.0.0,>=1.0.0->langchain-deepseek) (0.12.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain-deepseek) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-deepseek) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.11/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-deepseek) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.11/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-deepseek) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.11/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-deepseek) (2.32.3)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.11/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-deepseek) (0.25.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai<2.0.0,>=1.0.0->langchain-deepseek) (4.11.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai<2.0.0,>=1.0.0->langchain-deepseek) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.11/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai<2.0.0,>=1.0.0->langchain-deepseek) (0.11.0)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai<2.0.0,>=1.0.0->langchain-deepseek) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai<2.0.0,>=1.0.0->langchain-deepseek) (4.67.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.0->langchain-deepseek) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.0->langchain-deepseek) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.0->langchain-deepseek) (0.4.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai<2.0.0,>=1.0.0->langchain-deepseek) (2024.11.6)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai<3.0.0,>=1.109.1->langchain-openai<2.0.0,>=1.0.0->langchain-deepseek) (3.10)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-deepseek) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-deepseek) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-deepseek) (0.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-deepseek) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-deepseek) (2.3.0)\n",
      "\u001b[33mDEPRECATION: pytorch-lightning 1.7.7 has a non-standard dependency specifier torch>=1.9.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# !uv add langgraph\n",
    "\n",
    "!pip install -U langgraph\n",
    "!pip install -U langchain\n",
    "!pip install langchain-openai openai\n",
    "!pip install langchain-deepseek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f76dc057-7bf5-4c26-941c-d05a9f334cc3",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2025-11-03T14:42:09.618741Z",
     "iopub.status.busy": "2025-11-03T14:42:09.618536Z",
     "iopub.status.idle": "2025-11-03T14:42:09.622181Z",
     "shell.execute_reply": "2025-11-03T14:42:09.621753Z",
     "shell.execute_reply.started": "2025-11-03T14:42:09.618725Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.tools import tool, ToolRuntime\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "# 设置 DeepSeek 的 API 密钥（LangChain-OpenAI 仍然会查找 OPENAI_API_KEY）\n",
    "os.environ['DEEPSEEK_API_KEY'] = 'sk-943df854319e423ca178e68e4668ca5a'\n",
    "\n",
    "# 您可以尝试将 DEEPSEEK_API_KEY 的值赋给 OPENAI_API_KEY 环境变量\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv('DEEPSEEK_API_KEY') # 确保这个值是 DeepSeek 的 key\n",
    "\n",
    "# 关键：指定 DeepSeek 的 API 基础 URL\n",
    "DEEPSEEK_BASE_URL = \"https://api.deepseek.com/v1\"\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    model=\"deepseek-chat\", # 使用 DeepSeek 的模型名称\n",
    "    openai_api_base=DEEPSEEK_BASE_URL, # 指定 DeepSeek 的 URL\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "633bc160-d770-4466-a568-54b3848d63f6",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2025-11-03T13:56:13.159816Z",
     "iopub.status.busy": "2025-11-03T13:56:13.159623Z",
     "iopub.status.idle": "2025-11-03T13:56:13.165673Z",
     "shell.execute_reply": "2025-11-03T13:56:13.165270Z",
     "shell.execute_reply.started": "2025-11-03T13:56:13.159802Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'refine_topic': {'topic': 'ice cream and cats'}}\n",
      "{'generate_joke': {'joke': 'This is a joke about ice cream and cats'}}\n"
     ]
    }
   ],
   "source": [
    "from typing import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "  topic: str\n",
    "  joke: str\n",
    "\n",
    "\n",
    "def refine_topic(state: State):\n",
    "    return {\"topic\": state[\"topic\"] + \" and cats\"}\n",
    "\n",
    "\n",
    "def generate_joke(state: State):\n",
    "    return {\"joke\": f\"This is a joke about {state['topic']}\"}\n",
    "\n",
    "graph = (\n",
    "  StateGraph(State)\n",
    "  .add_node(refine_topic)\n",
    "  .add_node(generate_joke)\n",
    "  .add_edge(START, \"refine_topic\")\n",
    "  .add_edge(\"refine_topic\", \"generate_joke\")\n",
    "  .add_edge(\"generate_joke\", END)\n",
    "  .compile()\n",
    ")\n",
    "for chunk in graph.stream(\n",
    "    {\"topic\": \"ice cream\"},\n",
    "    stream_mode=\"updates\",  \n",
    "):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "707f5745-588b-499f-8f8d-e04f7c9d524c",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2025-11-03T13:56:37.102133Z",
     "iopub.status.busy": "2025-11-03T13:56:37.101903Z",
     "iopub.status.idle": "2025-11-03T13:56:37.111743Z",
     "shell.execute_reply": "2025-11-03T13:56:37.111395Z",
     "shell.execute_reply.started": "2025-11-03T13:56:37.102117Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((), {'node_1': {'foo': 'hi! foo'}})\n",
      "(('node_2:9e87b68d-9049-c9e5-5624-96ce0ebba66d',), {'subgraph_node_1': {'bar': 'bar'}})\n",
      "(('node_2:9e87b68d-9049-c9e5-5624-96ce0ebba66d',), {'subgraph_node_2': {'foo': 'hi! foobar'}})\n",
      "((), {'node_2': {'foo': 'hi! foobar'}})\n"
     ]
    }
   ],
   "source": [
    "from langgraph.graph import START, StateGraph\n",
    "from typing import TypedDict\n",
    "\n",
    "# Define subgraph\n",
    "class SubgraphState(TypedDict):\n",
    "    foo: str  # note that this key is shared with the parent graph state\n",
    "    bar: str\n",
    "\n",
    "def subgraph_node_1(state: SubgraphState):\n",
    "    return {\"bar\": \"bar\"}\n",
    "\n",
    "def subgraph_node_2(state: SubgraphState):\n",
    "    return {\"foo\": state[\"foo\"] + state[\"bar\"]}\n",
    "\n",
    "subgraph_builder = StateGraph(SubgraphState)\n",
    "subgraph_builder.add_node(subgraph_node_1)\n",
    "subgraph_builder.add_node(subgraph_node_2)\n",
    "subgraph_builder.add_edge(START, \"subgraph_node_1\")\n",
    "subgraph_builder.add_edge(\"subgraph_node_1\", \"subgraph_node_2\")\n",
    "subgraph = subgraph_builder.compile()\n",
    "\n",
    "# Define parent graph\n",
    "class ParentState(TypedDict):\n",
    "    foo: str\n",
    "\n",
    "def node_1(state: ParentState):\n",
    "    return {\"foo\": \"hi! \" + state[\"foo\"]}\n",
    "\n",
    "builder = StateGraph(ParentState)\n",
    "builder.add_node(\"node_1\", node_1)\n",
    "builder.add_node(\"node_2\", subgraph)\n",
    "builder.add_edge(START, \"node_1\")\n",
    "builder.add_edge(\"node_1\", \"node_2\")\n",
    "graph = builder.compile()\n",
    "\n",
    "for chunk in graph.stream(\n",
    "    {\"foo\": \"foo\"},\n",
    "    stream_mode=\"updates\",\n",
    "    # Set subgraphs=True to stream outputs from subgraphs\n",
    "    subgraphs=True,  \n",
    "):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2a75219f-c216-444b-9f8e-0fae86dd650f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T13:59:01.016332Z",
     "iopub.status.busy": "2025-11-03T13:59:01.016126Z",
     "iopub.status.idle": "2025-11-03T13:59:03.214556Z",
     "shell.execute_reply": "2025-11-03T13:59:03.214140Z",
     "shell.execute_reply.started": "2025-11-03T13:59:01.016318Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'step': 1, 'timestamp': '2025-11-03T13:59:01.017739+00:00', 'type': 'task', 'payload': {'id': 'bf91953e-ef1a-4e43-912d-8e549945f448', 'name': 'call_model', 'input': MyState(topic='ice cream', joke=''), 'triggers': ('branch:to:call_model',)}}\n",
      "{'step': 1, 'timestamp': '2025-11-03T13:59:03.212603+00:00', 'type': 'task_result', 'payload': {'id': 'bf91953e-ef1a-4e43-912d-8e549945f448', 'name': 'call_model', 'error': None, 'result': {'joke': \"Why did the ice cream truck break down?\\n\\nBecause it couldn't handle all the rocky road!\"}, 'interrupts': []}}\n"
     ]
    }
   ],
   "source": [
    "for chunk in graph.stream(\n",
    "    {\"topic\": \"ice cream\"},\n",
    "    stream_mode=\"debug\",  \n",
    "):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "59a3e10f-4b6e-435c-afa9-b13006da19e5",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2025-11-03T14:00:23.633389Z",
     "iopub.status.busy": "2025-11-03T14:00:23.633198Z",
     "iopub.status.idle": "2025-11-03T14:00:25.599588Z",
     "shell.execute_reply": "2025-11-03T14:00:25.599182Z",
     "shell.execute_reply.started": "2025-11-03T14:00:23.633376Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What| do| you| call| an| ice| cream| that|'s| always| telling| jokes|?\n",
      "\n",
      "|A| *|w|itty| scoop|*|!|"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langgraph.graph import StateGraph, START\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class MyState:\n",
    "    topic: str\n",
    "    joke: str = \"\"\n",
    "\n",
    "\n",
    "# model = init_chat_model(model=\"gpt-4o-mini\")\n",
    "\n",
    "def call_model(state: MyState):\n",
    "    \"\"\"Call the LLM to generate a joke about a topic\"\"\"\n",
    "    # Note that message events are emitted even when the LLM is run using .invoke rather than .stream\n",
    "    model_response = model.invoke(  \n",
    "        [\n",
    "            {\"role\": \"user\", \"content\": f\"Generate a joke about {state.topic}\"}\n",
    "        ]\n",
    "    )\n",
    "    return {\"joke\": model_response.content}\n",
    "\n",
    "graph = (\n",
    "    StateGraph(MyState)\n",
    "    .add_node(call_model)\n",
    "    .add_edge(START, \"call_model\")\n",
    "    .compile()\n",
    ")\n",
    "\n",
    "# The \"messages\" stream mode returns an iterator of tuples (message_chunk, metadata)\n",
    "# where message_chunk is the token streamed by the LLM and metadata is a dictionary\n",
    "# with information about the graph node where the LLM was called and other information\n",
    "for message_chunk, metadata in graph.stream(\n",
    "    {\"topic\": \"ice cream\"},\n",
    "    stream_mode=\"messages\",  \n",
    "):\n",
    "    if message_chunk.content:\n",
    "        print(message_chunk.content, end=\"|\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bf9a2648-f402-4392-9e5a-8c239bbf05f5",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2025-11-03T14:03:08.001495Z",
     "iopub.status.busy": "2025-11-03T14:03:08.001215Z",
     "iopub.status.idle": "2025-11-03T14:03:15.931164Z",
     "shell.execute_reply": "2025-11-03T14:03:15.930689Z",
     "shell.execute_reply.started": "2025-11-03T14:03:08.001474Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing joke...\n",
      "|Why| don|'t| cats| play| poker| in| the| jungle|?\n",
      "\n",
      "|Too| many| che|et|ahs|.||\n",
      "\n",
      "Writing poem...\n",
      "|A| box|,| a| sun|beam|,| a| vacant| chair|,\n",
      "|A| world| of| wonder| is| anywhere|.\n",
      "|With| em|erald| eyes| and| silent| paws|,\n",
      "|They| live| their| lives| by| their| own| laws|.\n",
      "\n",
      "|A| graceful| leap|,| a| tw|itching| tail|,\n",
      "|A| mighty| hunter| cannot| fail|.\n",
      "|Then| in| a| blink|,| a| liquid| curl|,\n",
      "|A| soft| and| r|umbling|,| gentle| whirl|.\n",
      "\n",
      "|They| de|ign| to| bless| us| with| a| blink|,\n",
      "|And| make| you| wonder| what| they| think|.\n",
      "|A| mystery| in| fur| and| grace|,\n",
      "|The| cat| has| found| its| proper| place|.||"
     ]
    }
   ],
   "source": [
    "from typing import TypedDict\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langgraph.graph import START, StateGraph\n",
    "\n",
    "# The joke_model is tagged with \"joke\"\n",
    "joke_model = model #init_chat_model(model=\"gpt-4o-mini\", tags=[\"joke\"])\n",
    "# The poem_model is tagged with \"poem\"\n",
    "poem_model = model #init_chat_model(model=\"gpt-4o-mini\", tags=[\"poem\"])\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "      topic: str\n",
    "      joke: str\n",
    "      poem: str\n",
    "\n",
    "\n",
    "async def call_model(state, config):\n",
    "      topic = state[\"topic\"]\n",
    "      print(\"Writing joke...\")\n",
    "      # Note: Passing the config through explicitly is required for python < 3.11\n",
    "      # Since context var support wasn't added before then: https://docs.python.org/3/library/asyncio-task.html#creating-tasks\n",
    "      # The config is passed through explicitly to ensure the context vars are propagated correctly\n",
    "      # This is required for Python < 3.11 when using async code. Please see the async section for more details\n",
    "      joke_response = await joke_model.ainvoke(\n",
    "            [{\"role\": \"user\", \"content\": f\"Write a joke about {topic}\"}],\n",
    "            config,\n",
    "      )\n",
    "      print(\"\\n\\nWriting poem...\")\n",
    "      poem_response = await poem_model.ainvoke(\n",
    "            [{\"role\": \"user\", \"content\": f\"Write a short poem about {topic}\"}],\n",
    "            config,\n",
    "      )\n",
    "      return {\"joke\": joke_response.content, \"poem\": poem_response.content}\n",
    "\n",
    "\n",
    "graph = (\n",
    "      StateGraph(State)\n",
    "      .add_node(call_model)\n",
    "      .add_edge(START, \"call_model\")\n",
    "      .compile()\n",
    ")\n",
    "\n",
    "# The stream_mode is set to \"messages\" to stream LLM tokens\n",
    "# The metadata contains information about the LLM invocation, including the tags\n",
    "async for msg, metadata in graph.astream(\n",
    "      {\"topic\": \"cats\"},\n",
    "      stream_mode=\"messages\",\n",
    "):\n",
    "    # if metadata[\"tags\"] == [\"joke\"]:\n",
    "    print(msg.content, end=\"|\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bda908b8-9f50-4534-8f87-bb0c2bc19aba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T14:04:23.292094Z",
     "iopub.status.busy": "2025-11-03T14:04:23.291873Z",
     "iopub.status.idle": "2025-11-03T14:04:23.298445Z",
     "shell.execute_reply": "2025-11-03T14:04:23.298041Z",
     "shell.execute_reply.started": "2025-11-03T14:04:23.292078Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'custom_key': 'Generating custom data inside node'}\n"
     ]
    }
   ],
   "source": [
    "from typing import TypedDict\n",
    "from langgraph.config import get_stream_writer\n",
    "from langgraph.graph import StateGraph, START\n",
    "\n",
    "class State(TypedDict):\n",
    "    query: str\n",
    "    answer: str\n",
    "\n",
    "def node(state: State):\n",
    "    # Get the stream writer to send custom data\n",
    "    writer = get_stream_writer()\n",
    "    # Emit a custom key-value pair (e.g., progress update)\n",
    "    writer({\"custom_key\": \"Generating custom data inside node\"})\n",
    "    return {\"answer\": \"some data\"}\n",
    "\n",
    "graph = (\n",
    "    StateGraph(State)\n",
    "    .add_node(node)\n",
    "    .add_edge(START, \"node\")\n",
    "    .compile()\n",
    ")\n",
    "\n",
    "inputs = {\"query\": \"example\"}\n",
    "\n",
    "# Set stream_mode=\"custom\" to receive the custom data in the stream\n",
    "for chunk in graph.stream(inputs, stream_mode=\"custom\"):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4eeb6ba8-c0ae-4c3a-9e4d-e3b21b48384e",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2025-11-03T14:05:51.934158Z",
     "iopub.status.busy": "2025-11-03T14:05:51.933920Z",
     "iopub.status.idle": "2025-11-03T14:05:51.987697Z",
     "shell.execute_reply": "2025-11-03T14:05:51.987312Z",
     "shell.execute_reply.started": "2025-11-03T14:05:51.934143Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "import json\n",
    "\n",
    "from typing import TypedDict\n",
    "from typing_extensions import Annotated\n",
    "from langgraph.graph import StateGraph, START\n",
    "\n",
    "from openai import AsyncOpenAI\n",
    "\n",
    "openai_client = AsyncOpenAI()\n",
    "model_name = \"gpt-4o-mini\"\n",
    "\n",
    "\n",
    "async def stream_tokens(model_name: str, messages: list[dict]):\n",
    "    response = await openai_client.chat.completions.create(\n",
    "        messages=messages, model=model_name, stream=True\n",
    "    )\n",
    "    role = None\n",
    "    async for chunk in response:\n",
    "        delta = chunk.choices[0].delta\n",
    "\n",
    "        if delta.role is not None:\n",
    "            role = delta.role\n",
    "\n",
    "        if delta.content:\n",
    "            yield {\"role\": role, \"content\": delta.content}\n",
    "\n",
    "\n",
    "# this is our tool\n",
    "async def get_items(place: str) -> str:\n",
    "    \"\"\"Use this tool to list items one might find in a place you're asked about.\"\"\"\n",
    "    writer = get_stream_writer()\n",
    "    response = \"\"\n",
    "    async for msg_chunk in stream_tokens(\n",
    "        model_name,\n",
    "        [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": (\n",
    "                    \"Can you tell me what kind of items \"\n",
    "                    f\"i might find in the following place: '{place}'. \"\n",
    "                    \"List at least 3 such items separating them by a comma. \"\n",
    "                    \"And include a brief description of each item.\"\n",
    "                ),\n",
    "            }\n",
    "        ],\n",
    "    ):\n",
    "        response += msg_chunk[\"content\"]\n",
    "        writer(msg_chunk)\n",
    "\n",
    "    return response\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list[dict], operator.add]\n",
    "\n",
    "\n",
    "# this is the tool-calling graph node\n",
    "async def call_tool(state: State):\n",
    "    ai_message = state[\"messages\"][-1]\n",
    "    tool_call = ai_message[\"tool_calls\"][-1]\n",
    "\n",
    "    function_name = tool_call[\"function\"][\"name\"]\n",
    "    if function_name != \"get_items\":\n",
    "        raise ValueError(f\"Tool {function_name} not supported\")\n",
    "\n",
    "    function_arguments = tool_call[\"function\"][\"arguments\"]\n",
    "    arguments = json.loads(function_arguments)\n",
    "\n",
    "    function_response = await get_items(**arguments)\n",
    "    tool_message = {\n",
    "        \"tool_call_id\": tool_call[\"id\"],\n",
    "        \"role\": \"tool\",\n",
    "        \"name\": function_name,\n",
    "        \"content\": function_response,\n",
    "    }\n",
    "    return {\"messages\": [tool_message]}\n",
    "\n",
    "\n",
    "graph = (\n",
    "    StateGraph(State)\n",
    "    .add_node(call_tool)\n",
    "    .add_edge(START, \"call_tool\")\n",
    "    .compile()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b55c2e2-ff14-4f3b-b64c-0bd3dc47e37a",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-11-03T14:12:34.308402Z",
     "iopub.status.idle": "2025-11-03T14:12:34.308554Z",
     "shell.execute_reply": "2025-11-03T14:12:34.308482Z",
     "shell.execute_reply.started": "2025-11-03T14:12:34.308475Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs = {\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"content\": None,\n",
    "            \"role\": \"assistant\",\n",
    "            \"tool_calls\": [\n",
    "                {\n",
    "                    \"id\": \"1\",\n",
    "                    \"function\": {\n",
    "                        \"arguments\": '{\"place\":\"bedroom\"}',\n",
    "                        \"name\": \"get_items\",\n",
    "                    },\n",
    "                    \"type\": \"function\",\n",
    "                }\n",
    "            ],\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "async for chunk in graph.astream(\n",
    "    inputs,\n",
    "    stream_mode=\"custom\",\n",
    "):\n",
    "    print(chunk[\"content\"], end=\"|\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9e3c8cb8-573f-4332-8013-6e9ed6650350",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T14:42:26.276143Z",
     "iopub.status.busy": "2025-11-03T14:42:26.275900Z",
     "iopub.status.idle": "2025-11-03T14:42:30.689373Z",
     "shell.execute_reply": "2025-11-03T14:42:30.688922Z",
     "shell.execute_reply.started": "2025-11-03T14:42:26.276127Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating joke...\n",
      "Why| did| the| ice| cream| get| invited| to| every| party|?\n",
      "\n",
      "|Because| it| was| always| so| good| at| breaking| the| \"|ice|\"| and| could| really| make| a| sund|ae|!|"
     ]
    }
   ],
   "source": [
    "from typing import TypedDict\n",
    "from langgraph.graph import START, StateGraph\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "# model = init_chat_model(model=\"gpt-4o-mini\")\n",
    "\n",
    "class State(TypedDict):\n",
    "    topic: str\n",
    "    joke: str\n",
    "\n",
    "# Accept config as an argument in the async node function\n",
    "async def call_model(state, config):\n",
    "    topic = state[\"topic\"]\n",
    "    print(\"Generating joke...\")\n",
    "    # Pass config to model.ainvoke() to ensure proper context propagation\n",
    "    joke_response = await model.ainvoke(  \n",
    "        [{\"role\": \"user\", \"content\": f\"Write a joke about {topic}\"}],\n",
    "        config,\n",
    "    )\n",
    "    return {\"joke\": joke_response.content}\n",
    "\n",
    "graph = (\n",
    "    StateGraph(State)\n",
    "    .add_node(call_model)\n",
    "    .add_edge(START, \"call_model\")\n",
    "    .compile()\n",
    ")\n",
    "\n",
    "# Set stream_mode=\"messages\" to stream LLM tokens\n",
    "async for chunk, metadata in graph.astream(\n",
    "    {\"topic\": \"ice cream\"},\n",
    "    stream_mode=\"messages\",  \n",
    "):\n",
    "    if chunk.content:\n",
    "        print(chunk.content, end=\"|\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "47e24a7d-5e94-4b01-bbd7-71954ea0c1f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T14:42:39.319759Z",
     "iopub.status.busy": "2025-11-03T14:42:39.319553Z",
     "iopub.status.idle": "2025-11-03T14:42:39.325165Z",
     "shell.execute_reply": "2025-11-03T14:42:39.324760Z",
     "shell.execute_reply.started": "2025-11-03T14:42:39.319744Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'custom_key': 'Streaming custom data while generating a joke'}\n"
     ]
    }
   ],
   "source": [
    "from typing import TypedDict\n",
    "from langgraph.types import StreamWriter\n",
    "\n",
    "class State(TypedDict):\n",
    "      topic: str\n",
    "      joke: str\n",
    "\n",
    "# Add writer as an argument in the function signature of the async node or tool\n",
    "# LangGraph will automatically pass the stream writer to the function\n",
    "async def generate_joke(state: State, writer: StreamWriter):  \n",
    "      writer({\"custom_key\": \"Streaming custom data while generating a joke\"})\n",
    "      return {\"joke\": f\"This is a joke about {state['topic']}\"}\n",
    "\n",
    "graph = (\n",
    "      StateGraph(State)\n",
    "      .add_node(generate_joke)\n",
    "      .add_edge(START, \"generate_joke\")\n",
    "      .compile()\n",
    ")\n",
    "\n",
    "# Set stream_mode=\"custom\" to receive the custom data in the stream  #\n",
    "async for chunk in graph.astream(\n",
    "      {\"topic\": \"ice cream\"},\n",
    "      stream_mode=\"custom\",\n",
    "):\n",
    "      print(chunk)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
